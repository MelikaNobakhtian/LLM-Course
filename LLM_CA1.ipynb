{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70cb2ebc14734b3e88a3d093f7221451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fe8c4631bc94cf6afc982e0c5160b58",
              "IPY_MODEL_daabb2c77aab4bb7a0dae874c552f47a",
              "IPY_MODEL_95b6055dc5344516a9c00a4b793d08cf"
            ],
            "layout": "IPY_MODEL_8a53e26d85924d22bac6372a78c38f97"
          }
        },
        "6fe8c4631bc94cf6afc982e0c5160b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a97063e462248c78e05a4a4ec732c7a",
            "placeholder": "​",
            "style": "IPY_MODEL_5343e329eb6f46fda28be508cda69e5a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "daabb2c77aab4bb7a0dae874c552f47a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52676669b91d4515a70f5092fceadb6c",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_494f798e5bce422eb4896da1d79bcb18",
            "value": 48
          }
        },
        "95b6055dc5344516a9c00a4b793d08cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feb2ca86979948f98149bc189b77989b",
            "placeholder": "​",
            "style": "IPY_MODEL_a2fed7dea5cc431188430a595139ddad",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.03kB/s]"
          }
        },
        "8a53e26d85924d22bac6372a78c38f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a97063e462248c78e05a4a4ec732c7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5343e329eb6f46fda28be508cda69e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52676669b91d4515a70f5092fceadb6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "494f798e5bce422eb4896da1d79bcb18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "feb2ca86979948f98149bc189b77989b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2fed7dea5cc431188430a595139ddad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38f5f88352d2404cbd07960af8f5841f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7ea343c25044fec8ad7172a35da1b1a",
              "IPY_MODEL_5cf708e4abe84fc0971617bb55357676",
              "IPY_MODEL_ccea90b4f86542639f7b9eea330acc06"
            ],
            "layout": "IPY_MODEL_9b3a995e4ddd4839ad45cb955770fb62"
          }
        },
        "d7ea343c25044fec8ad7172a35da1b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f5527b7fc3349d7b1b32fe607a1822f",
            "placeholder": "​",
            "style": "IPY_MODEL_24782d931ecc46a4a2912ec6a9b9353b",
            "value": "vocab.txt: 100%"
          }
        },
        "5cf708e4abe84fc0971617bb55357676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8455da9c745948c3868e0ec54cf95aba",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a8b74b76b724b818ad0bcffa6517140",
            "value": 231508
          }
        },
        "ccea90b4f86542639f7b9eea330acc06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eed23c1a3cb42e1b9b55634e012375f",
            "placeholder": "​",
            "style": "IPY_MODEL_fe8453884ed048dd8e3223dbd17d708c",
            "value": " 232k/232k [00:00&lt;00:00, 3.53MB/s]"
          }
        },
        "9b3a995e4ddd4839ad45cb955770fb62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f5527b7fc3349d7b1b32fe607a1822f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24782d931ecc46a4a2912ec6a9b9353b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8455da9c745948c3868e0ec54cf95aba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a8b74b76b724b818ad0bcffa6517140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5eed23c1a3cb42e1b9b55634e012375f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe8453884ed048dd8e3223dbd17d708c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e940d15cb7a4d93ad0d2b16df7eda86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b86a66e8e03b4f5eac7b1a9549ef18ad",
              "IPY_MODEL_1d37c88496ed4c968b0cbac3f2526cce",
              "IPY_MODEL_5c1e2e5a5a044ae9a1266b24d5b0f879"
            ],
            "layout": "IPY_MODEL_0724ead22a364cb896cef0af64df712e"
          }
        },
        "b86a66e8e03b4f5eac7b1a9549ef18ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b7d7057c4044f63bb93e53821faf256",
            "placeholder": "​",
            "style": "IPY_MODEL_a91135c5424f42348a7fa09c4c2b64ac",
            "value": "tokenizer.json: 100%"
          }
        },
        "1d37c88496ed4c968b0cbac3f2526cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e8d3f5aa81b43e3bef9112cdb9adbd5",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69da46adef0e42b7842fd5abd728da8b",
            "value": 466062
          }
        },
        "5c1e2e5a5a044ae9a1266b24d5b0f879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8a272962ac7496fb4275e4b55210f09",
            "placeholder": "​",
            "style": "IPY_MODEL_66f8d280c2ce488c97dbdba1a1621227",
            "value": " 466k/466k [00:00&lt;00:00, 2.52MB/s]"
          }
        },
        "0724ead22a364cb896cef0af64df712e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b7d7057c4044f63bb93e53821faf256": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a91135c5424f42348a7fa09c4c2b64ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e8d3f5aa81b43e3bef9112cdb9adbd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69da46adef0e42b7842fd5abd728da8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8a272962ac7496fb4275e4b55210f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f8d280c2ce488c97dbdba1a1621227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "690b526ccb2042c282bbfab945f6494b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_978dc85785b54c799d591df57ea25f6d",
              "IPY_MODEL_15bd6fa68ee74bc88e8c5c60efad7e4b",
              "IPY_MODEL_e5e68a8e52774623b264cb01684a5c29"
            ],
            "layout": "IPY_MODEL_33139be40bbb4be4879ba968e64b6619"
          }
        },
        "978dc85785b54c799d591df57ea25f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a35af8c30e02422a986fd7ad82c76c36",
            "placeholder": "​",
            "style": "IPY_MODEL_4b69024b950244ac97575fe24295f085",
            "value": "config.json: 100%"
          }
        },
        "15bd6fa68ee74bc88e8c5c60efad7e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_298c5dd327d5426da387640db6d3a910",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb253b0d261c47cba05143b4ed62b73e",
            "value": 570
          }
        },
        "e5e68a8e52774623b264cb01684a5c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_344132070aed464cb700aa4da1e6d2a8",
            "placeholder": "​",
            "style": "IPY_MODEL_76a45e41d59644ea8f6288050d914eca",
            "value": " 570/570 [00:00&lt;00:00, 39.5kB/s]"
          }
        },
        "33139be40bbb4be4879ba968e64b6619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a35af8c30e02422a986fd7ad82c76c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b69024b950244ac97575fe24295f085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "298c5dd327d5426da387640db6d3a910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb253b0d261c47cba05143b4ed62b73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "344132070aed464cb700aa4da1e6d2a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a45e41d59644ea8f6288050d914eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "938d769d409d4ba99e5c4521f947e223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14ecfe8d53e446a28df60eb9d5d0c140",
              "IPY_MODEL_a12325167f75483da157bffcb0625979",
              "IPY_MODEL_a947891ac03f4622af2b227c28900e3a"
            ],
            "layout": "IPY_MODEL_e9b93e25a5c4445c8deb6973f59530b8"
          }
        },
        "14ecfe8d53e446a28df60eb9d5d0c140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa8b43dd6dd64698876275b3b0fb92e9",
            "placeholder": "​",
            "style": "IPY_MODEL_058ca0481a494608bef8582c089b9eec",
            "value": "model.safetensors: 100%"
          }
        },
        "a12325167f75483da157bffcb0625979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce1bd8226494f81abf1ab1a6878c513",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_174fcb1621374f3e93a6dbcc33da9b31",
            "value": 440449768
          }
        },
        "a947891ac03f4622af2b227c28900e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ed744e6cecc4e18a4ce6f3bc7ff92a2",
            "placeholder": "​",
            "style": "IPY_MODEL_db5eece74cd04806892684ad95c9f3bf",
            "value": " 440M/440M [00:10&lt;00:00, 39.3MB/s]"
          }
        },
        "e9b93e25a5c4445c8deb6973f59530b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa8b43dd6dd64698876275b3b0fb92e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058ca0481a494608bef8582c089b9eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ce1bd8226494f81abf1ab1a6878c513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "174fcb1621374f3e93a6dbcc33da9b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ed744e6cecc4e18a4ce6f3bc7ff92a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db5eece74cd04806892684ad95c9f3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPOsZP3eGKmj"
      },
      "source": [
        "## CA 1, LLMs Spring 2024\n",
        "\n",
        "- **Name:** Melika Noubakhtian\n",
        "- **Student ID:** 4021305965008\n",
        "\n",
        "---\n",
        "### This is due on **April 2nd, 2024**, submitted via Microsoft Teams\n",
        "#### Your submission should be named using the following format: `CA1_LASTNAME_STUDENTID.ipynb`.\n",
        "\n",
        "### **IMPORTANT**: After copying this notebook to your Google Drive, please paste a link to it below. To get a publicly-accessible link, hit the *Share* button at the top right, then click \"Get shareable link\" and copy over the result. If you fail to do this, you will receive no credit for this homework!\n",
        "# ***LINK: https://colab.research.google.com/drive/1Yu-QpaQkKOLd4TFxSH2NcEOgymPe47B-?usp=sharing***\n",
        "\n",
        "---\n",
        "\n",
        "##### *How to do this problem set:*\n",
        "\n",
        "- Some questions require writing Python code and computing results, and the rest of them have written answers. For coding problems, you will have to fill out all code blocks that say `YOUR CODE HERE`.\n",
        "\n",
        "- For text-based answers, you should replace the text that says \"Write your answer here...\" with your actual answer.\n",
        "\n",
        "- There is no penalty for using AI assistance on this homework as long as you fully disclose it in the final cell of this notebook (this includes storing any prompts that you feed to large language models). That said, anyone caught using AI assistance without proper disclosure will receive a zero on the assignment (we have several automatic tools to detect such cases). We're literally allowing you to use it with no limitations, so there is no reason to lie!\n",
        "\n",
        "---\n",
        "\n",
        "##### *Academic honesty*\n",
        "\n",
        "- We will audit the Colab notebooks from a set number of students, chosen at random. The audits will check that the code you wrote actually generates the answers in your notebook. If you turn in correct answers on your notebook without code that actually generates those answers, we will consider this a serious case of cheating.\n",
        "\n",
        "- We will also run automatic checks of Colab notebooks for plagiarism. Copying code from others is also considered a serious case of cheating.\n",
        "\n",
        "---\n",
        "\n",
        "If you have any further questions or concerns, contact the TAs via Telegram:\n",
        "\n",
        "* [Mohammad Azimi](https://t.me/nooooooooppp)\n",
        "* [Sina Abbasi](https://t.me/SinaAbbasi1)  \n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Word Embeddings and Masked LMs (40 points)"
      ],
      "metadata": {
        "id": "sIGZBVK96ARd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.1 (5 points)"
      ],
      "metadata": {
        "id": "BgRQHomu9VDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we will start with `GloVe` [(Pennington et al.)](https://aclanthology.org/D14-1162.pdf) word embeddings. `GloVe` provides low-dimensional dense vectors representing words' semantics. The distance between `GloVe` embeddings captures the semantic relationships of words. We are using the `Gensim` library for  working with `GloVe` embeddings. Let's install `Gensim` and download the 6B token model. Also, we should unzip the model file. Running the cell below could take a few minutes."
      ],
      "metadata": {
        "id": "b-o6W_La6E6V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeSDN3i858zo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9a0cd2-4c3e-41dc-c8c0-420e7c6f74e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "--2024-04-02 17:08:04--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-04-02 17:08:04--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 38s  \n",
            "\n",
            "2024-04-02 17:10:43 (5.19 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  /content/glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip \"/content/glove.6B.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using the model file with 6 billion tokens containing 200-dimensional vectors. Running the cell below will create the word embedding model."
      ],
      "metadata": {
        "id": "bKVZeILG6KUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "glove_input_file = 'glove.6B.200d.txt'\n",
        "model = KeyedVectors.load_word2vec_format(glove_input_file, binary=False, no_header=True)"
      ],
      "metadata": {
        "id": "TrumleB96NFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to write the 5 most similar words to **computer**, **football**, **ocean**, **music**, and **artificial** along with their similarity scores."
      ],
      "metadata": {
        "id": "XdbyaunH6HLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## WRITE YOUR CODE HERE!\n",
        "model.most_similar('computer')[:5]"
      ],
      "metadata": {
        "id": "7q5ZZCk36Qqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd41849-2324-4600-a323-9b9fec4d25c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('computers', 0.8357723951339722),\n",
              " ('software', 0.7828460335731506),\n",
              " ('technology', 0.6907660961151123),\n",
              " ('pc', 0.6647984385490417),\n",
              " ('systems', 0.658431887626648)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar('football')[:5]"
      ],
      "metadata": {
        "id": "eKL2lMdlcdF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b569632d-d839-4822-e1d9-48303442c951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('soccer', 0.8105178475379944),\n",
              " ('basketball', 0.7896140813827515),\n",
              " ('league', 0.716710090637207),\n",
              " ('baseball', 0.7023130655288696),\n",
              " ('rugby', 0.7006953358650208)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar('ocean')[:5]"
      ],
      "metadata": {
        "id": "mejNEXLuchBl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7390d1f4-045c-417c-b7b4-09e0a96763dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sea', 0.7277445197105408),\n",
              " ('waters', 0.724154531955719),\n",
              " ('coast', 0.6972916126251221),\n",
              " ('atlantic', 0.6918381452560425),\n",
              " ('seas', 0.6812019348144531)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar('music')[:5]"
      ],
      "metadata": {
        "id": "V4n8N99zckVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "396f0e3d-9c9f-434c-bd2b-83ae05c5ff41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('musical', 0.7338810563087463),\n",
              " ('songs', 0.7253574728965759),\n",
              " ('pop', 0.6906009912490845),\n",
              " ('musicians', 0.6876541972160339),\n",
              " ('recording', 0.6848656535148621)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar('artifical')[:5]"
      ],
      "metadata": {
        "id": "8x_cpaUwcnae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e6d145-ba9a-4976-bcb4-2a78bd564cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('inseminations', 0.5080195665359497),\n",
              " ('alcohol-induced', 0.4810210168361664),\n",
              " ('2teaspoons', 0.4769013524055481),\n",
              " ('oligopolistic', 0.4658466875553131),\n",
              " ('80-point', 0.46400707960128784)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analogy** in word embeddings refers to performing algebraic operations on vectors to capture the most similar words to the resulting embedding. One of the most famous examples is the analogy *king - man + woman = queen*. In `Gensim`, we can apply analogies using the `most_similar` function. The `positive` argument receives a list of words and applies addition between their embeddings, while the `negative` argument receives a list of words to subtract their embeddings from the result. In our example, *king* and *woman* are in the positive list, while *man* is in the negative list.\n",
        "\n",
        "Let's explore more analogies and the power of `GloVe` embeddings. Write down five other analogies."
      ],
      "metadata": {
        "id": "bYKLguwx6df1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar(positive=['king', 'woman'], negative=['man'])"
      ],
      "metadata": {
        "id": "Q0IsfDLkczVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0efbe31a-2977-4dda-81ca-b03fa7ef0cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.6978678107261658),\n",
              " ('princess', 0.6081745028495789),\n",
              " ('monarch', 0.5889754891395569),\n",
              " ('throne', 0.5775108933448792),\n",
              " ('prince', 0.5750998258590698),\n",
              " ('elizabeth', 0.5463595986366272),\n",
              " ('daughter', 0.5399126410484314),\n",
              " ('kingdom', 0.5318052768707275),\n",
              " ('mother', 0.5168544054031372),\n",
              " ('crown', 0.5164473056793213)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## WRITE YOUR CODE HERE!\n",
        "def analogy(pos_word, pos_word_2, neg_word):\n",
        "    return model.most_similar(positive=[pos_word, pos_word_2], negative=[neg_word])"
      ],
      "metadata": {
        "id": "2AuwX7p96hnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analogy('mother', 'son', 'daughter')[:5]"
      ],
      "metadata": {
        "id": "KRnc-r26dWvW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5221501c-81c0-49ed-8688-8199672cc78f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('father', 0.9187806248664856),\n",
              " ('brother', 0.8050207495689392),\n",
              " ('grandfather', 0.7644326686859131),\n",
              " ('husband', 0.7391424179077148),\n",
              " ('uncle', 0.7305830121040344)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analogy('france', 'milan', 'paris')[:5]"
      ],
      "metadata": {
        "id": "teGETTIJdarJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e99a87-bb2f-447a-a4ac-b8bc73170673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('italy', 0.7033260464668274),\n",
              " ('juventus', 0.6320236921310425),\n",
              " ('ac', 0.6317757368087769),\n",
              " ('parma', 0.5991483330726624),\n",
              " ('roma', 0.5924952030181885)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analogy('love', 'shame', 'hate')[:5]"
      ],
      "metadata": {
        "id": "3NehQvogddey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e91673-30f4-4569-8e0f-a150aa1ad30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('joy', 0.5757980942726135),\n",
              " ('sorrow', 0.5513848066329956),\n",
              " ('goodbye', 0.5365443229675293),\n",
              " ('happiness', 0.5337100625038147),\n",
              " ('glory', 0.5321565866470337)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analogy('worst', 'good', 'bad')[:5]"
      ],
      "metadata": {
        "id": "lxlZlohKdiN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a94d9709-fb40-4f5b-a7ac-bee7ec00393f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('best', 0.6561789512634277),\n",
              " ('ever', 0.6481848359107971),\n",
              " ('better', 0.6061735153198242),\n",
              " ('one', 0.5882939696311951),\n",
              " ('only', 0.5789252519607544)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analogy('ronaldo','argentina', 'portugal')[:5]"
      ],
      "metadata": {
        "id": "s2S97OeMdmMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd08b2e4-d746-4c52-f9b8-d4fbab12e806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tevez', 0.6596886515617371),\n",
              " ('messi', 0.6545544266700745),\n",
              " ('ronaldinho', 0.605263888835907),\n",
              " ('higuain', 0.5921509861946106),\n",
              " ('argentine', 0.5809422135353088)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.2 (10 points)\n",
        "Let's visualize embeddings! We'll start with the following list of words. Extract the embedding for each word and reduce their dimensionality to 2 using the `t-SNE` [(Van der Maaten et al.)](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf) algorithm. Then, plot them on a scatter plot with their labels."
      ],
      "metadata": {
        "id": "SeuDs79G6ka1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adjustText"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVce15cu23Y5",
        "outputId": "9378602f-5116-4a9c-dfb3-a504d1b0881c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adjustText\n",
            "  Downloading adjustText-1.1.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from adjustText) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from adjustText) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from adjustText) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->adjustText) (1.16.0)\n",
            "Installing collected packages: adjustText\n",
            "Successfully installed adjustText-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "words = [\n",
        "    \"dolphin\", \"shark\", \"octopus\", \"jellyfish\", \"seahorse\",\n",
        "    \"turtle\", \"clownfish\", \"lobster\", \"starfish\", \"whale\",\n",
        "    \"eagle\", \"sparrow\", \"owl\", \"hummingbird\", \"penguin\",\n",
        "    \"toucan\", \"flamingo\", \"hawk\", \"parrot\", \"swan\",\n",
        "    \"england\", \"brazil\", \"japan\", \"australia\", \"india\",\n",
        "    \"germany\", \"canada\", \"france\", \"mexico\", \"russia\",\n",
        "    \"chicago\", \"paris\", \"tokyo\", \"london\", \"sydney\",\n",
        "    \"istanbul\", \"tehran\", \"cairo\", \"dubai\", \"mumbai\",\n",
        "    \"symphony\", \"jazz\", \"rock\", \"blues\", \"reggae\",\n",
        "    \"hip-hop\", \"country\", \"pop\", \"classical\", \"r&b\"\n",
        "]\n",
        "\n",
        "\n",
        "## WRITE YOUR CODE HERE!\n",
        "## Use 5 for perplexity of TSNE\n",
        "def plt_embedding(words, perp=5):\n",
        "    w_embeds = np.array([model[w] for w in words])\n",
        "    tsne_model = TSNE(n_components=2, perplexity=perp)\n",
        "    result = tsne_model.fit_transform(w_embeds)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.scatter(result[:,0], result[:,1], edgecolors='k', c='r')\n",
        "    for word, (x,y) in zip(words, result):\n",
        "        plt.text(x + 0.05, y + 0.05, word)\n",
        "\n",
        "plt_embedding(words)"
      ],
      "metadata": {
        "id": "6Lyv-iKm6niZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "06effc65-ccb1-4304-af4d-c0b0b596a117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze the plot and clusters of embeddings in a few sentences."
      ],
      "metadata": {
        "id": "TKgU9Dmq7JDP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyF5OBz9O-pK"
      },
      "source": [
        "***WRITE YOUR ANSWER HERE***\n",
        "\n",
        "According to the plot, we have three clusters: One cluster belongs to different kinds of animals. Another one includes cities, countries and etc. The last cluster represents a lot of music genres.\n",
        "\n",
        "Overll, it shows that the embedding of similar words are near in distance and also they are apart from the words that don't have many things in common. In Addition, in each cluster we can see that more similar words have shorter distance like shark, whale and dolphin."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.3 (15 points)\n",
        "Find the most similar words to **bat** and **charge** in GloVe."
      ],
      "metadata": {
        "id": "iJp6Kbyx7UNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## WRITE YOUR CODE HERE!\n",
        "model.most_similar('bat')"
      ],
      "metadata": {
        "id": "nXp1AQtl7hXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9893c79-1df6-4b68-f34f-724899c0a666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bats', 0.691724419593811),\n",
              " ('batting', 0.6160588264465332),\n",
              " ('balls', 0.5692734122276306),\n",
              " ('batted', 0.5530908107757568),\n",
              " ('toss', 0.5506128668785095),\n",
              " ('wicket', 0.5495278835296631),\n",
              " ('pitch', 0.5489361882209778),\n",
              " ('bowled', 0.5452010631561279),\n",
              " ('hitter', 0.5353438854217529),\n",
              " ('batsman', 0.5348091125488281)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar('charge')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB233qRcTzR9",
        "outputId": "28e58645-bb7b-41dd-b9d8-b2061090ac0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('charges', 0.8177176117897034),\n",
              " ('charged', 0.8067139983177185),\n",
              " ('charging', 0.6606977581977844),\n",
              " ('guilty', 0.6375356316566467),\n",
              " ('accused', 0.6239764094352722),\n",
              " ('for', 0.6172690987586975),\n",
              " ('responsible', 0.6007314920425415),\n",
              " ('month', 0.5919045805931091),\n",
              " ('while', 0.5750368237495422),\n",
              " ('counts', 0.5714022517204285)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, consider these sentences:\n",
        "* *The **bat** flew swiftly through the air.*\n",
        "* *He grabbed his **bat** and headed to the baseball field.*\n",
        "\n",
        "Or these sentences:\n",
        "* *I need to **charge** my phone before leaving.*\n",
        "* *He was arrested for **charge** of theft.*\n",
        "\n",
        "As you can see, a static vector cannot capture the meaning of a word in every context, and some words have very different meanings in different sentences. In this part, we will work with a masked language model, which captures contextual embeddings. Let's import necessary modules and load the `BERT` [(Devlin et al.)](https://aclanthology.org/N19-1423.pdf) model."
      ],
      "metadata": {
        "id": "JXQ5Y8b17m31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)"
      ],
      "metadata": {
        "id": "43wobVKF7n-1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "70cb2ebc14734b3e88a3d093f7221451",
            "6fe8c4631bc94cf6afc982e0c5160b58",
            "daabb2c77aab4bb7a0dae874c552f47a",
            "95b6055dc5344516a9c00a4b793d08cf",
            "8a53e26d85924d22bac6372a78c38f97",
            "8a97063e462248c78e05a4a4ec732c7a",
            "5343e329eb6f46fda28be508cda69e5a",
            "52676669b91d4515a70f5092fceadb6c",
            "494f798e5bce422eb4896da1d79bcb18",
            "feb2ca86979948f98149bc189b77989b",
            "a2fed7dea5cc431188430a595139ddad",
            "38f5f88352d2404cbd07960af8f5841f",
            "d7ea343c25044fec8ad7172a35da1b1a",
            "5cf708e4abe84fc0971617bb55357676",
            "ccea90b4f86542639f7b9eea330acc06",
            "9b3a995e4ddd4839ad45cb955770fb62",
            "1f5527b7fc3349d7b1b32fe607a1822f",
            "24782d931ecc46a4a2912ec6a9b9353b",
            "8455da9c745948c3868e0ec54cf95aba",
            "9a8b74b76b724b818ad0bcffa6517140",
            "5eed23c1a3cb42e1b9b55634e012375f",
            "fe8453884ed048dd8e3223dbd17d708c",
            "3e940d15cb7a4d93ad0d2b16df7eda86",
            "b86a66e8e03b4f5eac7b1a9549ef18ad",
            "1d37c88496ed4c968b0cbac3f2526cce",
            "5c1e2e5a5a044ae9a1266b24d5b0f879",
            "0724ead22a364cb896cef0af64df712e",
            "8b7d7057c4044f63bb93e53821faf256",
            "a91135c5424f42348a7fa09c4c2b64ac",
            "2e8d3f5aa81b43e3bef9112cdb9adbd5",
            "69da46adef0e42b7842fd5abd728da8b",
            "e8a272962ac7496fb4275e4b55210f09",
            "66f8d280c2ce488c97dbdba1a1621227",
            "690b526ccb2042c282bbfab945f6494b",
            "978dc85785b54c799d591df57ea25f6d",
            "15bd6fa68ee74bc88e8c5c60efad7e4b",
            "e5e68a8e52774623b264cb01684a5c29",
            "33139be40bbb4be4879ba968e64b6619",
            "a35af8c30e02422a986fd7ad82c76c36",
            "4b69024b950244ac97575fe24295f085",
            "298c5dd327d5426da387640db6d3a910",
            "fb253b0d261c47cba05143b4ed62b73e",
            "344132070aed464cb700aa4da1e6d2a8",
            "76a45e41d59644ea8f6288050d914eca",
            "938d769d409d4ba99e5c4521f947e223",
            "14ecfe8d53e446a28df60eb9d5d0c140",
            "a12325167f75483da157bffcb0625979",
            "a947891ac03f4622af2b227c28900e3a",
            "e9b93e25a5c4445c8deb6973f59530b8",
            "fa8b43dd6dd64698876275b3b0fb92e9",
            "058ca0481a494608bef8582c089b9eec",
            "3ce1bd8226494f81abf1ab1a6878c513",
            "174fcb1621374f3e93a6dbcc33da9b31",
            "1ed744e6cecc4e18a4ce6f3bc7ff92a2",
            "db5eece74cd04806892684ad95c9f3bf"
          ]
        },
        "outputId": "743e4be9-7580-4326-aae4-ec3fad0b9943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70cb2ebc14734b3e88a3d093f7221451"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38f5f88352d2404cbd07960af8f5841f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e940d15cb7a4d93ad0d2b16df7eda86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "690b526ccb2042c282bbfab945f6494b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "938d769d409d4ba99e5c4521f947e223"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below demonstrates how to input data into the `BERT` model and how to capture word embeddings from each layer."
      ],
      "metadata": {
        "id": "-BDfI_D27tQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = \"This is a test\"\n",
        "test_encodings = tokenizer(test_input, return_tensors='pt')\n",
        "output = model(**test_encodings)\n",
        "print(\"Num. of BERT layers:\", len(output[-1]))\n",
        "print(\"Dimensionality of each layer output (batch_size * num_tokens * embedding_dim): \", output[-1][0].size())"
      ],
      "metadata": {
        "id": "-_ziH3XV7uM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a9f4c9d-19f5-429d-8424-612a445978d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num. of BERT layers: 13\n",
            "Dimensionality of each layer output (batch_size * num_tokens * embedding_dim):  torch.Size([1, 6, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, you should analyze the embeddings of the word **bat** in the output of each layer of the `BERT` model for the provided sentences. First, identify the location of the **bat** embedding within the output of each layer for both sentences. Next, calculate the `cosine similarity` between the **bat** embeddings for each layer. Finally, examine the similarity levels of the **bat** embeddings between the two sentences across the various layers of the `BERT` model."
      ],
      "metadata": {
        "id": "sW3W66Hi7z_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## WRITE YOUR CODE HERE!\n",
        "bat_1 = \"The bat flew swiftly through the air.\"\n",
        "bat_2 = \"He grabbed his bat and headed to the baseball field.\"\n",
        "\n",
        "## Encode input sentences\n",
        "encodings_1 = tokenizer(bat_1, return_tensors='pt')\n",
        "encodings_2 = tokenizer(bat_2, return_tensors='pt')\n",
        "\n",
        "## Find 'bat' location in each sentence\n",
        "token_words_1 = tokenizer.convert_ids_to_tokens(encodings_1['input_ids'][0])\n",
        "token_words_2 = tokenizer.convert_ids_to_tokens(encodings_2['input_ids'][0])\n",
        "print(\"First Sentence Tokens: \", token_words_1)\n",
        "print(\"Second Sentence Tokens: \", token_words_2)\n",
        "print(\"\")\n",
        "bat_idx_1 = token_words_1.index('bat')\n",
        "bat_idx_2 = token_words_2.index('bat')\n",
        "print(f\"'Bat' is the {bat_idx_1 + 1}-th token in the first sentence.\")\n",
        "print(f\"'Bat' is the {bat_idx_2 + 1}-th token in the second sentence.\")\n",
        "\n",
        "## 'bat' embeddings in each layer\n",
        "output_1 = model(**encodings_1)\n",
        "output_2 = model(**encodings_2)\n",
        "\n",
        "## first sentence embeddings\n",
        "layer_embeds_1 = output_1[-1]\n",
        "bat_embeds_1 = []\n",
        "for embeds in layer_embeds_1:\n",
        "    bat_embeds_1.append(embeds[0][bat_idx_1])\n",
        "\n",
        "## second sentence embeddings\n",
        "layer_embeds_2 = output_2[-1]\n",
        "bat_embeds_2 = []\n",
        "for embeds in layer_embeds_2:\n",
        "    bat_embeds_2.append(embeds[0][bat_idx_2])"
      ],
      "metadata": {
        "id": "PGwfHB7x71D-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28fc4bb2-3bc2-416c-fb55-7cdf9ebc53d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Sentence Tokens:  ['[CLS]', 'the', 'bat', 'flew', 'swiftly', 'through', 'the', 'air', '.', '[SEP]']\n",
            "Second Sentence Tokens:  ['[CLS]', 'he', 'grabbed', 'his', 'bat', 'and', 'headed', 'to', 'the', 'baseball', 'field', '.', '[SEP]']\n",
            "\n",
            "'Bat' is the 3-th token in the first sentence.\n",
            "'Bat' is the 5-th token in the second sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## calculate similarities between embedding of a sentence in different layers\n",
        "sim_in_sent_1 = []\n",
        "print(\"Sentence: \", bat_1)\n",
        "for idx, embed in enumerate(bat_embeds_1):\n",
        "    cs = torch.nn.CosineSimilarity(dim=0)\n",
        "    sim = [cs(embed, emb).item() for emb in bat_embeds_1]\n",
        "    sim_in_sent_1.append(sim)\n",
        "    print(f'Similarities of bat embedding in layer {idx+1} with other layers:')\n",
        "    for index, s in enumerate(sim):\n",
        "        print(f'layer {index+1}: {s}')\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50OOTmrp7ep1",
        "outputId": "4617c54b-d5bf-464e-d71d-356dd0dc3845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  The bat flew swiftly through the air.\n",
            "Similarities of bat embedding in layer 1 with other layers:\n",
            "layer 1: 0.9999998807907104\n",
            "layer 2: 0.8621749877929688\n",
            "layer 3: 0.781710147857666\n",
            "layer 4: 0.7144138216972351\n",
            "layer 5: 0.6443666815757751\n",
            "layer 6: 0.5523238182067871\n",
            "layer 7: 0.5134338140487671\n",
            "layer 8: 0.4943072199821472\n",
            "layer 9: 0.4487411677837372\n",
            "layer 10: 0.4124460518360138\n",
            "layer 11: 0.3807237446308136\n",
            "layer 12: 0.33071255683898926\n",
            "layer 13: 0.2967490255832672\n",
            "\n",
            "Similarities of bat embedding in layer 2 with other layers:\n",
            "layer 1: 0.8621749877929688\n",
            "layer 2: 1.000000238418579\n",
            "layer 3: 0.912908673286438\n",
            "layer 4: 0.8354040384292603\n",
            "layer 5: 0.7721546292304993\n",
            "layer 6: 0.6855823993682861\n",
            "layer 7: 0.6467705965042114\n",
            "layer 8: 0.6110156774520874\n",
            "layer 9: 0.5658700466156006\n",
            "layer 10: 0.5176666975021362\n",
            "layer 11: 0.492256760597229\n",
            "layer 12: 0.4395450949668884\n",
            "layer 13: 0.3717334568500519\n",
            "\n",
            "Similarities of bat embedding in layer 3 with other layers:\n",
            "layer 1: 0.781710147857666\n",
            "layer 2: 0.912908673286438\n",
            "layer 3: 1.0000001192092896\n",
            "layer 4: 0.9281933307647705\n",
            "layer 5: 0.8643631339073181\n",
            "layer 6: 0.7776095867156982\n",
            "layer 7: 0.727459728717804\n",
            "layer 8: 0.6906121969223022\n",
            "layer 9: 0.6402321457862854\n",
            "layer 10: 0.5875630974769592\n",
            "layer 11: 0.5638687610626221\n",
            "layer 12: 0.4980272948741913\n",
            "layer 13: 0.4232100248336792\n",
            "\n",
            "Similarities of bat embedding in layer 4 with other layers:\n",
            "layer 1: 0.7144138216972351\n",
            "layer 2: 0.8354040384292603\n",
            "layer 3: 0.9281933307647705\n",
            "layer 4: 0.9999998807907104\n",
            "layer 5: 0.9389843940734863\n",
            "layer 6: 0.8554447889328003\n",
            "layer 7: 0.8067927360534668\n",
            "layer 8: 0.7688377499580383\n",
            "layer 9: 0.7185089588165283\n",
            "layer 10: 0.6648768186569214\n",
            "layer 11: 0.6352026462554932\n",
            "layer 12: 0.565339982509613\n",
            "layer 13: 0.48754462599754333\n",
            "\n",
            "Similarities of bat embedding in layer 5 with other layers:\n",
            "layer 1: 0.6443666815757751\n",
            "layer 2: 0.7721546292304993\n",
            "layer 3: 0.8643631339073181\n",
            "layer 4: 0.9389843940734863\n",
            "layer 5: 1.000000238418579\n",
            "layer 6: 0.9320138692855835\n",
            "layer 7: 0.8765853047370911\n",
            "layer 8: 0.839596688747406\n",
            "layer 9: 0.7896348834037781\n",
            "layer 10: 0.7406846880912781\n",
            "layer 11: 0.7153646349906921\n",
            "layer 12: 0.646373450756073\n",
            "layer 13: 0.569635272026062\n",
            "\n",
            "Similarities of bat embedding in layer 6 with other layers:\n",
            "layer 1: 0.5523238182067871\n",
            "layer 2: 0.6855823993682861\n",
            "layer 3: 0.7776095867156982\n",
            "layer 4: 0.8554447889328003\n",
            "layer 5: 0.9320138692855835\n",
            "layer 6: 0.9999999403953552\n",
            "layer 7: 0.9511849880218506\n",
            "layer 8: 0.9128580093383789\n",
            "layer 9: 0.8565607070922852\n",
            "layer 10: 0.8039232492446899\n",
            "layer 11: 0.779147207736969\n",
            "layer 12: 0.7163907885551453\n",
            "layer 13: 0.6283079385757446\n",
            "\n",
            "Similarities of bat embedding in layer 7 with other layers:\n",
            "layer 1: 0.5134338140487671\n",
            "layer 2: 0.6467705965042114\n",
            "layer 3: 0.727459728717804\n",
            "layer 4: 0.8067927360534668\n",
            "layer 5: 0.8765853047370911\n",
            "layer 6: 0.9511849880218506\n",
            "layer 7: 1.0\n",
            "layer 8: 0.9619691967964172\n",
            "layer 9: 0.9067329168319702\n",
            "layer 10: 0.8535688519477844\n",
            "layer 11: 0.8275275826454163\n",
            "layer 12: 0.766135036945343\n",
            "layer 13: 0.6681140065193176\n",
            "\n",
            "Similarities of bat embedding in layer 8 with other layers:\n",
            "layer 1: 0.4943072199821472\n",
            "layer 2: 0.6110156774520874\n",
            "layer 3: 0.6906121969223022\n",
            "layer 4: 0.7688377499580383\n",
            "layer 5: 0.839596688747406\n",
            "layer 6: 0.9128580093383789\n",
            "layer 7: 0.9619691967964172\n",
            "layer 8: 0.9999999403953552\n",
            "layer 9: 0.9515561461448669\n",
            "layer 10: 0.9094138145446777\n",
            "layer 11: 0.8767318725585938\n",
            "layer 12: 0.8008807301521301\n",
            "layer 13: 0.7078966498374939\n",
            "\n",
            "Similarities of bat embedding in layer 9 with other layers:\n",
            "layer 1: 0.4487411677837372\n",
            "layer 2: 0.5658700466156006\n",
            "layer 3: 0.6402321457862854\n",
            "layer 4: 0.7185089588165283\n",
            "layer 5: 0.7896348834037781\n",
            "layer 6: 0.8565607070922852\n",
            "layer 7: 0.9067329168319702\n",
            "layer 8: 0.9515561461448669\n",
            "layer 9: 1.0000001192092896\n",
            "layer 10: 0.9629611968994141\n",
            "layer 11: 0.9217398166656494\n",
            "layer 12: 0.8258992433547974\n",
            "layer 13: 0.7242116332054138\n",
            "\n",
            "Similarities of bat embedding in layer 10 with other layers:\n",
            "layer 1: 0.4124460518360138\n",
            "layer 2: 0.5176666975021362\n",
            "layer 3: 0.5875630974769592\n",
            "layer 4: 0.6648768186569214\n",
            "layer 5: 0.7406846880912781\n",
            "layer 6: 0.8039232492446899\n",
            "layer 7: 0.8535688519477844\n",
            "layer 8: 0.9094138145446777\n",
            "layer 9: 0.9629611968994141\n",
            "layer 10: 1.0\n",
            "layer 11: 0.9533420205116272\n",
            "layer 12: 0.8415190577507019\n",
            "layer 13: 0.749667227268219\n",
            "\n",
            "Similarities of bat embedding in layer 11 with other layers:\n",
            "layer 1: 0.3807237446308136\n",
            "layer 2: 0.492256760597229\n",
            "layer 3: 0.5638687610626221\n",
            "layer 4: 0.6352026462554932\n",
            "layer 5: 0.7153646349906921\n",
            "layer 6: 0.779147207736969\n",
            "layer 7: 0.8275275826454163\n",
            "layer 8: 0.8767318725585938\n",
            "layer 9: 0.9217398166656494\n",
            "layer 10: 0.9533420205116272\n",
            "layer 11: 0.9999999403953552\n",
            "layer 12: 0.9126066565513611\n",
            "layer 13: 0.8075646758079529\n",
            "\n",
            "Similarities of bat embedding in layer 12 with other layers:\n",
            "layer 1: 0.33071255683898926\n",
            "layer 2: 0.4395450949668884\n",
            "layer 3: 0.4980272948741913\n",
            "layer 4: 0.565339982509613\n",
            "layer 5: 0.646373450756073\n",
            "layer 6: 0.7163907885551453\n",
            "layer 7: 0.766135036945343\n",
            "layer 8: 0.8008807301521301\n",
            "layer 9: 0.8258992433547974\n",
            "layer 10: 0.8415190577507019\n",
            "layer 11: 0.9126066565513611\n",
            "layer 12: 1.0\n",
            "layer 13: 0.8972669243812561\n",
            "\n",
            "Similarities of bat embedding in layer 13 with other layers:\n",
            "layer 1: 0.2967490255832672\n",
            "layer 2: 0.3717334568500519\n",
            "layer 3: 0.4232100248336792\n",
            "layer 4: 0.48754462599754333\n",
            "layer 5: 0.569635272026062\n",
            "layer 6: 0.6283079385757446\n",
            "layer 7: 0.6681140065193176\n",
            "layer 8: 0.7078966498374939\n",
            "layer 9: 0.7242116332054138\n",
            "layer 10: 0.749667227268219\n",
            "layer 11: 0.8075646758079529\n",
            "layer 12: 0.8972669243812561\n",
            "layer 13: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sim_in_sent_2 = []\n",
        "print(\"Sentence: \", bat_2)\n",
        "for idx, embed in enumerate(bat_embeds_2):\n",
        "    cs = torch.nn.CosineSimilarity(dim=0)\n",
        "    sim = [cs(embed, emb).item() for emb in bat_embeds_2]\n",
        "    sim_in_sent_2.append(sim)\n",
        "    print(f'Similarities of bat embedding in layer {idx+1} with other layers:')\n",
        "    for index, s in enumerate(sim):\n",
        "        print(f'layer {index+1}: {s}')\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW5p540i9VU-",
        "outputId": "9ccdf34b-2af9-4b90-d778-c28e73cd6914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  He grabbed his bat and headed to the baseball field.\n",
            "Similarities of bat embedding in layer 1 with other layers:\n",
            "layer 1: 1.000000238418579\n",
            "layer 2: 0.8436372876167297\n",
            "layer 3: 0.733452558517456\n",
            "layer 4: 0.6136446595191956\n",
            "layer 5: 0.5095905661582947\n",
            "layer 6: 0.449752539396286\n",
            "layer 7: 0.4189205765724182\n",
            "layer 8: 0.3985862135887146\n",
            "layer 9: 0.3793875277042389\n",
            "layer 10: 0.35721543431282043\n",
            "layer 11: 0.31594058871269226\n",
            "layer 12: 0.2585364282131195\n",
            "layer 13: 0.24260784685611725\n",
            "\n",
            "Similarities of bat embedding in layer 2 with other layers:\n",
            "layer 1: 0.8436372876167297\n",
            "layer 2: 0.9999998807907104\n",
            "layer 3: 0.8646106719970703\n",
            "layer 4: 0.7694479823112488\n",
            "layer 5: 0.6635932922363281\n",
            "layer 6: 0.5960752367973328\n",
            "layer 7: 0.56358802318573\n",
            "layer 8: 0.5275972485542297\n",
            "layer 9: 0.49851498007774353\n",
            "layer 10: 0.47605133056640625\n",
            "layer 11: 0.44283100962638855\n",
            "layer 12: 0.38933634757995605\n",
            "layer 13: 0.35410410165786743\n",
            "\n",
            "Similarities of bat embedding in layer 3 with other layers:\n",
            "layer 1: 0.733452558517456\n",
            "layer 2: 0.8646106719970703\n",
            "layer 3: 0.9999998807907104\n",
            "layer 4: 0.880714476108551\n",
            "layer 5: 0.77717524766922\n",
            "layer 6: 0.7046041488647461\n",
            "layer 7: 0.6661288738250732\n",
            "layer 8: 0.6269659996032715\n",
            "layer 9: 0.5817859172821045\n",
            "layer 10: 0.5470720529556274\n",
            "layer 11: 0.5092206001281738\n",
            "layer 12: 0.45632874965667725\n",
            "layer 13: 0.4029960632324219\n",
            "\n",
            "Similarities of bat embedding in layer 4 with other layers:\n",
            "layer 1: 0.6136446595191956\n",
            "layer 2: 0.7694479823112488\n",
            "layer 3: 0.880714476108551\n",
            "layer 4: 0.9999998807907104\n",
            "layer 5: 0.9086071252822876\n",
            "layer 6: 0.8282060623168945\n",
            "layer 7: 0.7930318117141724\n",
            "layer 8: 0.7432175874710083\n",
            "layer 9: 0.6887052059173584\n",
            "layer 10: 0.6526297926902771\n",
            "layer 11: 0.6137363314628601\n",
            "layer 12: 0.5535421371459961\n",
            "layer 13: 0.49734771251678467\n",
            "\n",
            "Similarities of bat embedding in layer 5 with other layers:\n",
            "layer 1: 0.5095905661582947\n",
            "layer 2: 0.6635932922363281\n",
            "layer 3: 0.77717524766922\n",
            "layer 4: 0.9086071252822876\n",
            "layer 5: 1.0000001192092896\n",
            "layer 6: 0.9369374513626099\n",
            "layer 7: 0.8927568197250366\n",
            "layer 8: 0.8431878089904785\n",
            "layer 9: 0.7827611565589905\n",
            "layer 10: 0.7391438484191895\n",
            "layer 11: 0.6906853914260864\n",
            "layer 12: 0.6400972604751587\n",
            "layer 13: 0.5659287571907043\n",
            "\n",
            "Similarities of bat embedding in layer 6 with other layers:\n",
            "layer 1: 0.449752539396286\n",
            "layer 2: 0.5960752367973328\n",
            "layer 3: 0.7046041488647461\n",
            "layer 4: 0.8282060623168945\n",
            "layer 5: 0.9369374513626099\n",
            "layer 6: 0.9999998807907104\n",
            "layer 7: 0.9549516439437866\n",
            "layer 8: 0.8968761563301086\n",
            "layer 9: 0.837640106678009\n",
            "layer 10: 0.7946930527687073\n",
            "layer 11: 0.7374085783958435\n",
            "layer 12: 0.6907482147216797\n",
            "layer 13: 0.5947227478027344\n",
            "\n",
            "Similarities of bat embedding in layer 7 with other layers:\n",
            "layer 1: 0.4189205765724182\n",
            "layer 2: 0.56358802318573\n",
            "layer 3: 0.6661288738250732\n",
            "layer 4: 0.7930318117141724\n",
            "layer 5: 0.8927568197250366\n",
            "layer 6: 0.9549516439437866\n",
            "layer 7: 1.0\n",
            "layer 8: 0.9452775120735168\n",
            "layer 9: 0.8918306827545166\n",
            "layer 10: 0.8487662672996521\n",
            "layer 11: 0.789441704750061\n",
            "layer 12: 0.7318426966667175\n",
            "layer 13: 0.6295018792152405\n",
            "\n",
            "Similarities of bat embedding in layer 8 with other layers:\n",
            "layer 1: 0.3985862135887146\n",
            "layer 2: 0.5275972485542297\n",
            "layer 3: 0.6269659996032715\n",
            "layer 4: 0.7432175874710083\n",
            "layer 5: 0.8431878089904785\n",
            "layer 6: 0.8968761563301086\n",
            "layer 7: 0.9452775120735168\n",
            "layer 8: 1.0000001192092896\n",
            "layer 9: 0.9541151523590088\n",
            "layer 10: 0.9127146601676941\n",
            "layer 11: 0.8443353176116943\n",
            "layer 12: 0.7736076712608337\n",
            "layer 13: 0.6724920272827148\n",
            "\n",
            "Similarities of bat embedding in layer 9 with other layers:\n",
            "layer 1: 0.3793875277042389\n",
            "layer 2: 0.49851498007774353\n",
            "layer 3: 0.5817859172821045\n",
            "layer 4: 0.6887052059173584\n",
            "layer 5: 0.7827611565589905\n",
            "layer 6: 0.837640106678009\n",
            "layer 7: 0.8918306827545166\n",
            "layer 8: 0.9541151523590088\n",
            "layer 9: 0.9999998807907104\n",
            "layer 10: 0.9629859924316406\n",
            "layer 11: 0.8891177177429199\n",
            "layer 12: 0.8075892925262451\n",
            "layer 13: 0.702485203742981\n",
            "\n",
            "Similarities of bat embedding in layer 10 with other layers:\n",
            "layer 1: 0.35721543431282043\n",
            "layer 2: 0.47605133056640625\n",
            "layer 3: 0.5470720529556274\n",
            "layer 4: 0.6526297926902771\n",
            "layer 5: 0.7391438484191895\n",
            "layer 6: 0.7946930527687073\n",
            "layer 7: 0.8487662672996521\n",
            "layer 8: 0.9127146601676941\n",
            "layer 9: 0.9629859924316406\n",
            "layer 10: 0.9999998807907104\n",
            "layer 11: 0.9309702515602112\n",
            "layer 12: 0.8413821458816528\n",
            "layer 13: 0.7317798137664795\n",
            "\n",
            "Similarities of bat embedding in layer 11 with other layers:\n",
            "layer 1: 0.31594058871269226\n",
            "layer 2: 0.44283100962638855\n",
            "layer 3: 0.5092206001281738\n",
            "layer 4: 0.6137363314628601\n",
            "layer 5: 0.6906853914260864\n",
            "layer 6: 0.7374085783958435\n",
            "layer 7: 0.789441704750061\n",
            "layer 8: 0.8443353176116943\n",
            "layer 9: 0.8891177177429199\n",
            "layer 10: 0.9309702515602112\n",
            "layer 11: 1.0000001192092896\n",
            "layer 12: 0.9274936318397522\n",
            "layer 13: 0.816063642501831\n",
            "\n",
            "Similarities of bat embedding in layer 12 with other layers:\n",
            "layer 1: 0.2585364282131195\n",
            "layer 2: 0.38933634757995605\n",
            "layer 3: 0.45632874965667725\n",
            "layer 4: 0.5535421371459961\n",
            "layer 5: 0.6400972604751587\n",
            "layer 6: 0.6907482147216797\n",
            "layer 7: 0.7318426966667175\n",
            "layer 8: 0.7736076712608337\n",
            "layer 9: 0.8075892925262451\n",
            "layer 10: 0.8413821458816528\n",
            "layer 11: 0.9274936318397522\n",
            "layer 12: 1.0\n",
            "layer 13: 0.8970633745193481\n",
            "\n",
            "Similarities of bat embedding in layer 13 with other layers:\n",
            "layer 1: 0.24260784685611725\n",
            "layer 2: 0.35410410165786743\n",
            "layer 3: 0.4029960632324219\n",
            "layer 4: 0.49734771251678467\n",
            "layer 5: 0.5659287571907043\n",
            "layer 6: 0.5947227478027344\n",
            "layer 7: 0.6295018792152405\n",
            "layer 8: 0.6724920272827148\n",
            "layer 9: 0.702485203742981\n",
            "layer 10: 0.7317798137664795\n",
            "layer 11: 0.816063642501831\n",
            "layer 12: 0.8970633745193481\n",
            "layer 13: 0.9999999403953552\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## similarity across sentences\n",
        "sim_across_sent = []\n",
        "for idx, embed in enumerate(bat_embeds_1):\n",
        "    cs = torch.nn.CosineSimilarity(dim=0)\n",
        "    print(f'Similarities of bat embedding of layer {idx+1} of first sentence with embeddings of second sentecne:')\n",
        "    sim = [cs(embed, emb).item() for emb in bat_embeds_2]\n",
        "    sim_across_sent.append(sim)\n",
        "    for index, sim in enumerate(sim):\n",
        "        print(f'layer {index+1}: {sim}')\n",
        "    print()"
      ],
      "metadata": {
        "id": "zpOpkSjnboeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ac41a7-a4a0-4538-eebc-d26ac8a73223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarities of bat embedding of layer 1 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.9575225114822388\n",
            "layer 2: 0.8128214478492737\n",
            "layer 3: 0.7087081670761108\n",
            "layer 4: 0.595879852771759\n",
            "layer 5: 0.48949527740478516\n",
            "layer 6: 0.4352138638496399\n",
            "layer 7: 0.40453147888183594\n",
            "layer 8: 0.38784313201904297\n",
            "layer 9: 0.3689630925655365\n",
            "layer 10: 0.3456370532512665\n",
            "layer 11: 0.3058454692363739\n",
            "layer 12: 0.24393567442893982\n",
            "layer 13: 0.23307716846466064\n",
            "\n",
            "Similarities of bat embedding of layer 2 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.8322256803512573\n",
            "layer 2: 0.8337299227714539\n",
            "layer 3: 0.7391198873519897\n",
            "layer 4: 0.6528811454772949\n",
            "layer 5: 0.5566089153289795\n",
            "layer 6: 0.5122699737548828\n",
            "layer 7: 0.48538145422935486\n",
            "layer 8: 0.45212745666503906\n",
            "layer 9: 0.42541468143463135\n",
            "layer 10: 0.39828136563301086\n",
            "layer 11: 0.3561543822288513\n",
            "layer 12: 0.3032477796077728\n",
            "layer 13: 0.2725682854652405\n",
            "\n",
            "Similarities of bat embedding of layer 3 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.7590745687484741\n",
            "layer 2: 0.7605555057525635\n",
            "layer 3: 0.7908402681350708\n",
            "layer 4: 0.6965150833129883\n",
            "layer 5: 0.6084855198860168\n",
            "layer 6: 0.5681326985359192\n",
            "layer 7: 0.5366442799568176\n",
            "layer 8: 0.5090501308441162\n",
            "layer 9: 0.47477173805236816\n",
            "layer 10: 0.43897774815559387\n",
            "layer 11: 0.40343916416168213\n",
            "layer 12: 0.3538738191127777\n",
            "layer 13: 0.30760183930397034\n",
            "\n",
            "Similarities of bat embedding of layer 4 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.6951830387115479\n",
            "layer 2: 0.7065121531486511\n",
            "layer 3: 0.7504897713661194\n",
            "layer 4: 0.7525650262832642\n",
            "layer 5: 0.664527416229248\n",
            "layer 6: 0.6293864250183105\n",
            "layer 7: 0.6076876521110535\n",
            "layer 8: 0.5784620046615601\n",
            "layer 9: 0.5431179404258728\n",
            "layer 10: 0.5045753717422485\n",
            "layer 11: 0.4692055881023407\n",
            "layer 12: 0.4199349880218506\n",
            "layer 13: 0.3698467016220093\n",
            "\n",
            "Similarities of bat embedding of layer 5 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.6266636252403259\n",
            "layer 2: 0.6470659375190735\n",
            "layer 3: 0.6902623176574707\n",
            "layer 4: 0.7001299262046814\n",
            "layer 5: 0.6812034249305725\n",
            "layer 6: 0.6550571918487549\n",
            "layer 7: 0.6398455500602722\n",
            "layer 8: 0.6159374117851257\n",
            "layer 9: 0.5846269130706787\n",
            "layer 10: 0.547089159488678\n",
            "layer 11: 0.5189088582992554\n",
            "layer 12: 0.4769493639469147\n",
            "layer 13: 0.4194062650203705\n",
            "\n",
            "Similarities of bat embedding of layer 6 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.5402775406837463\n",
            "layer 2: 0.5699631571769714\n",
            "layer 3: 0.6095956563949585\n",
            "layer 4: 0.6300251483917236\n",
            "layer 5: 0.6442288160324097\n",
            "layer 6: 0.668319821357727\n",
            "layer 7: 0.6536936163902283\n",
            "layer 8: 0.6294497847557068\n",
            "layer 9: 0.5958500504493713\n",
            "layer 10: 0.5632400512695312\n",
            "layer 11: 0.5377846956253052\n",
            "layer 12: 0.5062593221664429\n",
            "layer 13: 0.4307728409767151\n",
            "\n",
            "Similarities of bat embedding of layer 7 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.5025615692138672\n",
            "layer 2: 0.5340479016304016\n",
            "layer 3: 0.5671499967575073\n",
            "layer 4: 0.6001310348510742\n",
            "layer 5: 0.6130807399749756\n",
            "layer 6: 0.6457040905952454\n",
            "layer 7: 0.6693581342697144\n",
            "layer 8: 0.6441705226898193\n",
            "layer 9: 0.6218765377998352\n",
            "layer 10: 0.5907175540924072\n",
            "layer 11: 0.5670052170753479\n",
            "layer 12: 0.5334168076515198\n",
            "layer 13: 0.45274946093559265\n",
            "\n",
            "Similarities of bat embedding of layer 8 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.4820096492767334\n",
            "layer 2: 0.5137679576873779\n",
            "layer 3: 0.5436483025550842\n",
            "layer 4: 0.5751962661743164\n",
            "layer 5: 0.5947747230529785\n",
            "layer 6: 0.6237019300460815\n",
            "layer 7: 0.6527765393257141\n",
            "layer 8: 0.6561663150787354\n",
            "layer 9: 0.6439189314842224\n",
            "layer 10: 0.61576247215271\n",
            "layer 11: 0.586410403251648\n",
            "layer 12: 0.5444236993789673\n",
            "layer 13: 0.4709504544734955\n",
            "\n",
            "Similarities of bat embedding of layer 9 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.4392569661140442\n",
            "layer 2: 0.4712887406349182\n",
            "layer 3: 0.4953819513320923\n",
            "layer 4: 0.5273262858390808\n",
            "layer 5: 0.5487295985221863\n",
            "layer 6: 0.5759110450744629\n",
            "layer 7: 0.6091890335083008\n",
            "layer 8: 0.6233247518539429\n",
            "layer 9: 0.6398158073425293\n",
            "layer 10: 0.6140135526657104\n",
            "layer 11: 0.5866068601608276\n",
            "layer 12: 0.5383753776550293\n",
            "layer 13: 0.4610372483730316\n",
            "\n",
            "Similarities of bat embedding of layer 10 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.40105533599853516\n",
            "layer 2: 0.4281039834022522\n",
            "layer 3: 0.4536736011505127\n",
            "layer 4: 0.48910269141197205\n",
            "layer 5: 0.5167682766914368\n",
            "layer 6: 0.5428450107574463\n",
            "layer 7: 0.5774075984954834\n",
            "layer 8: 0.5974141955375671\n",
            "layer 9: 0.6202280521392822\n",
            "layer 10: 0.6194900870323181\n",
            "layer 11: 0.5883027911186218\n",
            "layer 12: 0.5423336625099182\n",
            "layer 13: 0.47448310256004333\n",
            "\n",
            "Similarities of bat embedding of layer 11 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.3728640079498291\n",
            "layer 2: 0.4112204611301422\n",
            "layer 3: 0.43666863441467285\n",
            "layer 4: 0.47267675399780273\n",
            "layer 5: 0.5025793313980103\n",
            "layer 6: 0.5322116613388062\n",
            "layer 7: 0.570720911026001\n",
            "layer 8: 0.5831844210624695\n",
            "layer 9: 0.5995624661445618\n",
            "layer 10: 0.6006869077682495\n",
            "layer 11: 0.6181025505065918\n",
            "layer 12: 0.5873768329620361\n",
            "layer 13: 0.5030141472816467\n",
            "\n",
            "Similarities of bat embedding of layer 12 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.3331087827682495\n",
            "layer 2: 0.37147122621536255\n",
            "layer 3: 0.3957686126232147\n",
            "layer 4: 0.4243569076061249\n",
            "layer 5: 0.46123114228248596\n",
            "layer 6: 0.4958345890045166\n",
            "layer 7: 0.5379299521446228\n",
            "layer 8: 0.5444796681404114\n",
            "layer 9: 0.5455202460289001\n",
            "layer 10: 0.5419090986251831\n",
            "layer 11: 0.5781745314598083\n",
            "layer 12: 0.6321281790733337\n",
            "layer 13: 0.5471782684326172\n",
            "\n",
            "Similarities of bat embedding of layer 13 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.2994011640548706\n",
            "layer 2: 0.31468337774276733\n",
            "layer 3: 0.3348506689071655\n",
            "layer 4: 0.36477309465408325\n",
            "layer 5: 0.40148109197616577\n",
            "layer 6: 0.4273105263710022\n",
            "layer 7: 0.4604151248931885\n",
            "layer 8: 0.47519028186798096\n",
            "layer 9: 0.4748671054840088\n",
            "layer 10: 0.47927388548851013\n",
            "layer 11: 0.5041855573654175\n",
            "layer 12: 0.5653847455978394\n",
            "layer 13: 0.568511962890625\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do the same for **charge** provided sentences."
      ],
      "metadata": {
        "id": "YgP6DU-y8Ap9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## WRITE YOUR CODE HERE!\n",
        "charge_1 = \"I need to charge my phone before leaving.\"\n",
        "charge_2 = \"He was arrested for charge of theft.\"\n",
        "\n",
        "## Encode input sentences\n",
        "encodings_1 = tokenizer(charge_1, return_tensors='pt')\n",
        "encodings_2 = tokenizer(charge_2, return_tensors='pt')\n",
        "\n",
        "## Find 'charge' location in each sentence\n",
        "token_words_1 = tokenizer.convert_ids_to_tokens(encodings_1['input_ids'][0])\n",
        "token_words_2 = tokenizer.convert_ids_to_tokens(encodings_2['input_ids'][0])\n",
        "print(\"First Sentence Tokens: \", token_words_1)\n",
        "print(\"Second Sentence Tokens: \", token_words_2)\n",
        "print(\"\")\n",
        "charge_idx_1 = token_words_1.index('charge')\n",
        "charge_idx_2 = token_words_2.index('charge')\n",
        "print(f\"'Charge' is the {charge_idx_1 + 1}-th token in the first sentence.\")\n",
        "print(f\"'Charge' is the {charge_idx_2 + 1}-th token in the second sentence.\")\n",
        "\n",
        "## 'charge' embeddings in each layer\n",
        "output_1 = model(**encodings_1)\n",
        "output_2 = model(**encodings_2)\n",
        "\n",
        "## first sentence embeddings\n",
        "layer_embeds_1 = output_1[-1]\n",
        "charge_embeds_1 = []\n",
        "for embeds in layer_embeds_1:\n",
        "    charge_embeds_1.append(embeds[0][charge_idx_1])\n",
        "\n",
        "## second sentence embeddings\n",
        "layer_embeds_2 = output_2[-1]\n",
        "charge_embeds_2 = []\n",
        "for embeds in layer_embeds_2:\n",
        "    charge_embeds_2.append(embeds[0][charge_idx_2])"
      ],
      "metadata": {
        "id": "CP2buXR98BNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40699486-7c98-4ddf-977f-90dd4e425e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Sentence Tokens:  ['[CLS]', 'i', 'need', 'to', 'charge', 'my', 'phone', 'before', 'leaving', '.', '[SEP]']\n",
            "Second Sentence Tokens:  ['[CLS]', 'he', 'was', 'arrested', 'for', 'charge', 'of', 'theft', '.', '[SEP]']\n",
            "\n",
            "'Charge' is the 5-th token in the first sentence.\n",
            "'Charge' is the 6-th token in the second sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## calculate similarities between embedding of a sentence in different layers\n",
        "sim_in_sent_1 = []\n",
        "print(\"Sentence: \", charge_1)\n",
        "for idx, embed in enumerate(charge_embeds_1):\n",
        "    cs = torch.nn.CosineSimilarity(dim=0)\n",
        "    sim = [cs(embed, emb).item() for emb in charge_embeds_1]\n",
        "    sim_in_sent_1.append(sim)\n",
        "    print(f'Similarities of charge embedding in layer {idx+1} with other layers:')\n",
        "    for index, s in enumerate(sim):\n",
        "        print(f'layer {index+1}: {s}')\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jJDFk0w95nB",
        "outputId": "d3df738f-e044-4015-fe88-08169f7da402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  I need to charge my phone before leaving.\n",
            "Similarities of charge embedding in layer 1 with other layers:\n",
            "layer 1: 1.0\n",
            "layer 2: 0.7846546769142151\n",
            "layer 3: 0.653886616230011\n",
            "layer 4: 0.5747884511947632\n",
            "layer 5: 0.465848833322525\n",
            "layer 6: 0.43371447920799255\n",
            "layer 7: 0.39811405539512634\n",
            "layer 8: 0.3655730187892914\n",
            "layer 9: 0.30940109491348267\n",
            "layer 10: 0.267306387424469\n",
            "layer 11: 0.2265523076057434\n",
            "layer 12: 0.20400312542915344\n",
            "layer 13: 0.192621648311615\n",
            "\n",
            "Similarities of charge embedding in layer 2 with other layers:\n",
            "layer 1: 0.7846546769142151\n",
            "layer 2: 1.0\n",
            "layer 3: 0.8840153217315674\n",
            "layer 4: 0.790054202079773\n",
            "layer 5: 0.689701497554779\n",
            "layer 6: 0.6436135172843933\n",
            "layer 7: 0.5861057639122009\n",
            "layer 8: 0.553778350353241\n",
            "layer 9: 0.48481541872024536\n",
            "layer 10: 0.4388442635536194\n",
            "layer 11: 0.39872580766677856\n",
            "layer 12: 0.37641867995262146\n",
            "layer 13: 0.32226940989494324\n",
            "\n",
            "Similarities of charge embedding in layer 3 with other layers:\n",
            "layer 1: 0.653886616230011\n",
            "layer 2: 0.8840153217315674\n",
            "layer 3: 1.0\n",
            "layer 4: 0.9135647416114807\n",
            "layer 5: 0.8155354857444763\n",
            "layer 6: 0.7610346078872681\n",
            "layer 7: 0.6866959929466248\n",
            "layer 8: 0.645266056060791\n",
            "layer 9: 0.5689719319343567\n",
            "layer 10: 0.522356390953064\n",
            "layer 11: 0.47844383120536804\n",
            "layer 12: 0.4531157612800598\n",
            "layer 13: 0.3701574206352234\n",
            "\n",
            "Similarities of charge embedding in layer 4 with other layers:\n",
            "layer 1: 0.5747884511947632\n",
            "layer 2: 0.790054202079773\n",
            "layer 3: 0.9135647416114807\n",
            "layer 4: 0.9999998807907104\n",
            "layer 5: 0.8918138742446899\n",
            "layer 6: 0.8387923836708069\n",
            "layer 7: 0.7633322477340698\n",
            "layer 8: 0.7170294523239136\n",
            "layer 9: 0.6385528445243835\n",
            "layer 10: 0.5879001021385193\n",
            "layer 11: 0.5389086604118347\n",
            "layer 12: 0.5088871121406555\n",
            "layer 13: 0.41314220428466797\n",
            "\n",
            "Similarities of charge embedding in layer 5 with other layers:\n",
            "layer 1: 0.465848833322525\n",
            "layer 2: 0.689701497554779\n",
            "layer 3: 0.8155354857444763\n",
            "layer 4: 0.8918138742446899\n",
            "layer 5: 1.0\n",
            "layer 6: 0.9407678842544556\n",
            "layer 7: 0.8753505945205688\n",
            "layer 8: 0.8274748921394348\n",
            "layer 9: 0.7402620315551758\n",
            "layer 10: 0.687293529510498\n",
            "layer 11: 0.6316033601760864\n",
            "layer 12: 0.5899114608764648\n",
            "layer 13: 0.4764755666255951\n",
            "\n",
            "Similarities of charge embedding in layer 6 with other layers:\n",
            "layer 1: 0.43371447920799255\n",
            "layer 2: 0.6436135172843933\n",
            "layer 3: 0.7610346078872681\n",
            "layer 4: 0.8387923836708069\n",
            "layer 5: 0.9407678842544556\n",
            "layer 6: 1.0000001192092896\n",
            "layer 7: 0.9374357461929321\n",
            "layer 8: 0.892729640007019\n",
            "layer 9: 0.8098903894424438\n",
            "layer 10: 0.7521582841873169\n",
            "layer 11: 0.693483829498291\n",
            "layer 12: 0.6486070156097412\n",
            "layer 13: 0.5189729928970337\n",
            "\n",
            "Similarities of charge embedding in layer 7 with other layers:\n",
            "layer 1: 0.39811405539512634\n",
            "layer 2: 0.5861057639122009\n",
            "layer 3: 0.6866959929466248\n",
            "layer 4: 0.7633322477340698\n",
            "layer 5: 0.8753505945205688\n",
            "layer 6: 0.9374357461929321\n",
            "layer 7: 0.9999999403953552\n",
            "layer 8: 0.9473814368247986\n",
            "layer 9: 0.8723797798156738\n",
            "layer 10: 0.812077522277832\n",
            "layer 11: 0.7445489168167114\n",
            "layer 12: 0.6908045411109924\n",
            "layer 13: 0.5603888630867004\n",
            "\n",
            "Similarities of charge embedding in layer 8 with other layers:\n",
            "layer 1: 0.3655730187892914\n",
            "layer 2: 0.553778350353241\n",
            "layer 3: 0.645266056060791\n",
            "layer 4: 0.7170294523239136\n",
            "layer 5: 0.8274748921394348\n",
            "layer 6: 0.892729640007019\n",
            "layer 7: 0.9473814368247986\n",
            "layer 8: 1.0000001192092896\n",
            "layer 9: 0.9327537417411804\n",
            "layer 10: 0.8707720041275024\n",
            "layer 11: 0.7976592779159546\n",
            "layer 12: 0.7359962463378906\n",
            "layer 13: 0.6085768938064575\n",
            "\n",
            "Similarities of charge embedding in layer 9 with other layers:\n",
            "layer 1: 0.30940109491348267\n",
            "layer 2: 0.48481541872024536\n",
            "layer 3: 0.5689719319343567\n",
            "layer 4: 0.6385528445243835\n",
            "layer 5: 0.7402620315551758\n",
            "layer 6: 0.8098903894424438\n",
            "layer 7: 0.8723797798156738\n",
            "layer 8: 0.9327537417411804\n",
            "layer 9: 1.0000001192092896\n",
            "layer 10: 0.9456868171691895\n",
            "layer 11: 0.8704007267951965\n",
            "layer 12: 0.7968732118606567\n",
            "layer 13: 0.6677529215812683\n",
            "\n",
            "Similarities of charge embedding in layer 10 with other layers:\n",
            "layer 1: 0.267306387424469\n",
            "layer 2: 0.4388442635536194\n",
            "layer 3: 0.522356390953064\n",
            "layer 4: 0.5879001021385193\n",
            "layer 5: 0.687293529510498\n",
            "layer 6: 0.7521582841873169\n",
            "layer 7: 0.812077522277832\n",
            "layer 8: 0.8707720041275024\n",
            "layer 9: 0.9456868171691895\n",
            "layer 10: 0.9999998211860657\n",
            "layer 11: 0.9395832419395447\n",
            "layer 12: 0.8617540001869202\n",
            "layer 13: 0.7235174775123596\n",
            "\n",
            "Similarities of charge embedding in layer 11 with other layers:\n",
            "layer 1: 0.2265523076057434\n",
            "layer 2: 0.39872580766677856\n",
            "layer 3: 0.47844383120536804\n",
            "layer 4: 0.5389086604118347\n",
            "layer 5: 0.6316033601760864\n",
            "layer 6: 0.693483829498291\n",
            "layer 7: 0.7445489168167114\n",
            "layer 8: 0.7976592779159546\n",
            "layer 9: 0.8704007267951965\n",
            "layer 10: 0.9395832419395447\n",
            "layer 11: 1.0\n",
            "layer 12: 0.9397163391113281\n",
            "layer 13: 0.7926167249679565\n",
            "\n",
            "Similarities of charge embedding in layer 12 with other layers:\n",
            "layer 1: 0.20400312542915344\n",
            "layer 2: 0.37641867995262146\n",
            "layer 3: 0.4531157612800598\n",
            "layer 4: 0.5088871121406555\n",
            "layer 5: 0.5899114608764648\n",
            "layer 6: 0.6486070156097412\n",
            "layer 7: 0.6908045411109924\n",
            "layer 8: 0.7359962463378906\n",
            "layer 9: 0.7968732118606567\n",
            "layer 10: 0.8617540001869202\n",
            "layer 11: 0.9397163391113281\n",
            "layer 12: 1.0000001192092896\n",
            "layer 13: 0.8696603178977966\n",
            "\n",
            "Similarities of charge embedding in layer 13 with other layers:\n",
            "layer 1: 0.192621648311615\n",
            "layer 2: 0.32226940989494324\n",
            "layer 3: 0.3701574206352234\n",
            "layer 4: 0.41314220428466797\n",
            "layer 5: 0.4764755666255951\n",
            "layer 6: 0.5189729928970337\n",
            "layer 7: 0.5603888630867004\n",
            "layer 8: 0.6085768938064575\n",
            "layer 9: 0.6677529215812683\n",
            "layer 10: 0.7235174775123596\n",
            "layer 11: 0.7926167249679565\n",
            "layer 12: 0.8696603178977966\n",
            "layer 13: 1.000000238418579\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## calculate similarities between embedding of a sentence in different layers\n",
        "sim_in_sent_2 = []\n",
        "print(\"Sentence: \", charge_2)\n",
        "for idx, embed in enumerate(charge_embeds_2):\n",
        "    cs = torch.nn.CosineSimilarity(dim=0)\n",
        "    sim = [cs(embed, emb).item() for emb in charge_embeds_2]\n",
        "    sim_in_sent_2.append(sim)\n",
        "    print(f'Similarities of charge embedding in layer {idx+1} with other layers:')\n",
        "    for index, s in enumerate(sim):\n",
        "        print(f'layer {index+1}: {s}')\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIVTRdM2_CGt",
        "outputId": "eb4581ed-edc4-435d-b5f2-af183072d83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  He was arrested for charge of theft.\n",
            "Similarities of charge embedding in layer 1 with other layers:\n",
            "layer 1: 1.0000001192092896\n",
            "layer 2: 0.7820063829421997\n",
            "layer 3: 0.6712489724159241\n",
            "layer 4: 0.6039261221885681\n",
            "layer 5: 0.5241208672523499\n",
            "layer 6: 0.4640491008758545\n",
            "layer 7: 0.3842926621437073\n",
            "layer 8: 0.33836451172828674\n",
            "layer 9: 0.2549557685852051\n",
            "layer 10: 0.23217695951461792\n",
            "layer 11: 0.20942100882530212\n",
            "layer 12: 0.1473187506198883\n",
            "layer 13: 0.14583633840084076\n",
            "\n",
            "Similarities of charge embedding in layer 2 with other layers:\n",
            "layer 1: 0.7820063829421997\n",
            "layer 2: 1.0\n",
            "layer 3: 0.9033633470535278\n",
            "layer 4: 0.8080854415893555\n",
            "layer 5: 0.7138571739196777\n",
            "layer 6: 0.6567652225494385\n",
            "layer 7: 0.5771202445030212\n",
            "layer 8: 0.524849534034729\n",
            "layer 9: 0.45568305253982544\n",
            "layer 10: 0.4210677444934845\n",
            "layer 11: 0.40106096863746643\n",
            "layer 12: 0.337318480014801\n",
            "layer 13: 0.2830500602722168\n",
            "\n",
            "Similarities of charge embedding in layer 3 with other layers:\n",
            "layer 1: 0.6712489724159241\n",
            "layer 2: 0.9033633470535278\n",
            "layer 3: 0.9999999403953552\n",
            "layer 4: 0.8906604051589966\n",
            "layer 5: 0.7925926446914673\n",
            "layer 6: 0.7272859215736389\n",
            "layer 7: 0.6372040510177612\n",
            "layer 8: 0.5850366353988647\n",
            "layer 9: 0.5232799649238586\n",
            "layer 10: 0.47479546070098877\n",
            "layer 11: 0.45076149702072144\n",
            "layer 12: 0.3908696472644806\n",
            "layer 13: 0.30904078483581543\n",
            "\n",
            "Similarities of charge embedding in layer 4 with other layers:\n",
            "layer 1: 0.6039261221885681\n",
            "layer 2: 0.8080854415893555\n",
            "layer 3: 0.8906604051589966\n",
            "layer 4: 1.0\n",
            "layer 5: 0.9037595987319946\n",
            "layer 6: 0.829349160194397\n",
            "layer 7: 0.7351153492927551\n",
            "layer 8: 0.6724568009376526\n",
            "layer 9: 0.6066908240318298\n",
            "layer 10: 0.5678175091743469\n",
            "layer 11: 0.5153229832649231\n",
            "layer 12: 0.45789462327957153\n",
            "layer 13: 0.3568779230117798\n",
            "\n",
            "Similarities of charge embedding in layer 5 with other layers:\n",
            "layer 1: 0.5241208672523499\n",
            "layer 2: 0.7138571739196777\n",
            "layer 3: 0.7925926446914673\n",
            "layer 4: 0.9037595987319946\n",
            "layer 5: 1.0000001192092896\n",
            "layer 6: 0.921127200126648\n",
            "layer 7: 0.81606125831604\n",
            "layer 8: 0.7465669512748718\n",
            "layer 9: 0.6723474860191345\n",
            "layer 10: 0.6248054504394531\n",
            "layer 11: 0.5647355914115906\n",
            "layer 12: 0.5138213038444519\n",
            "layer 13: 0.40904319286346436\n",
            "\n",
            "Similarities of charge embedding in layer 6 with other layers:\n",
            "layer 1: 0.4640491008758545\n",
            "layer 2: 0.6567652225494385\n",
            "layer 3: 0.7272859215736389\n",
            "layer 4: 0.829349160194397\n",
            "layer 5: 0.921127200126648\n",
            "layer 6: 0.9999999403953552\n",
            "layer 7: 0.9014226198196411\n",
            "layer 8: 0.8173370361328125\n",
            "layer 9: 0.746009886264801\n",
            "layer 10: 0.6900678873062134\n",
            "layer 11: 0.6259276866912842\n",
            "layer 12: 0.5766220688819885\n",
            "layer 13: 0.4602195620536804\n",
            "\n",
            "Similarities of charge embedding in layer 7 with other layers:\n",
            "layer 1: 0.3842926621437073\n",
            "layer 2: 0.5771202445030212\n",
            "layer 3: 0.6372040510177612\n",
            "layer 4: 0.7351153492927551\n",
            "layer 5: 0.81606125831604\n",
            "layer 6: 0.9014226198196411\n",
            "layer 7: 1.0\n",
            "layer 8: 0.916688084602356\n",
            "layer 9: 0.8397747278213501\n",
            "layer 10: 0.7792761921882629\n",
            "layer 11: 0.7063484191894531\n",
            "layer 12: 0.6473212838172913\n",
            "layer 13: 0.5151377320289612\n",
            "\n",
            "Similarities of charge embedding in layer 8 with other layers:\n",
            "layer 1: 0.33836451172828674\n",
            "layer 2: 0.524849534034729\n",
            "layer 3: 0.5850366353988647\n",
            "layer 4: 0.6724568009376526\n",
            "layer 5: 0.7465669512748718\n",
            "layer 6: 0.8173370361328125\n",
            "layer 7: 0.916688084602356\n",
            "layer 8: 0.9999997615814209\n",
            "layer 9: 0.9106361865997314\n",
            "layer 10: 0.8422954082489014\n",
            "layer 11: 0.7650852203369141\n",
            "layer 12: 0.6922999024391174\n",
            "layer 13: 0.5630425214767456\n",
            "\n",
            "Similarities of charge embedding in layer 9 with other layers:\n",
            "layer 1: 0.2549557685852051\n",
            "layer 2: 0.45568305253982544\n",
            "layer 3: 0.5232799649238586\n",
            "layer 4: 0.6066908240318298\n",
            "layer 5: 0.6723474860191345\n",
            "layer 6: 0.746009886264801\n",
            "layer 7: 0.8397747278213501\n",
            "layer 8: 0.9106361865997314\n",
            "layer 9: 1.0000001192092896\n",
            "layer 10: 0.9076012372970581\n",
            "layer 11: 0.820490837097168\n",
            "layer 12: 0.7313851714134216\n",
            "layer 13: 0.6000286340713501\n",
            "\n",
            "Similarities of charge embedding in layer 10 with other layers:\n",
            "layer 1: 0.23217695951461792\n",
            "layer 2: 0.4210677444934845\n",
            "layer 3: 0.47479546070098877\n",
            "layer 4: 0.5678175091743469\n",
            "layer 5: 0.6248054504394531\n",
            "layer 6: 0.6900678873062134\n",
            "layer 7: 0.7792761921882629\n",
            "layer 8: 0.8422954082489014\n",
            "layer 9: 0.9076012372970581\n",
            "layer 10: 0.9999999403953552\n",
            "layer 11: 0.9100885987281799\n",
            "layer 12: 0.7947344183921814\n",
            "layer 13: 0.6614037752151489\n",
            "\n",
            "Similarities of charge embedding in layer 11 with other layers:\n",
            "layer 1: 0.20942100882530212\n",
            "layer 2: 0.40106096863746643\n",
            "layer 3: 0.45076149702072144\n",
            "layer 4: 0.5153229832649231\n",
            "layer 5: 0.5647355914115906\n",
            "layer 6: 0.6259276866912842\n",
            "layer 7: 0.7063484191894531\n",
            "layer 8: 0.7650852203369141\n",
            "layer 9: 0.820490837097168\n",
            "layer 10: 0.9100885987281799\n",
            "layer 11: 0.9999998807907104\n",
            "layer 12: 0.89714515209198\n",
            "layer 13: 0.7576097249984741\n",
            "\n",
            "Similarities of charge embedding in layer 12 with other layers:\n",
            "layer 1: 0.1473187506198883\n",
            "layer 2: 0.337318480014801\n",
            "layer 3: 0.3908696472644806\n",
            "layer 4: 0.45789462327957153\n",
            "layer 5: 0.5138213038444519\n",
            "layer 6: 0.5766220688819885\n",
            "layer 7: 0.6473212838172913\n",
            "layer 8: 0.6922999024391174\n",
            "layer 9: 0.7313851714134216\n",
            "layer 10: 0.7947344183921814\n",
            "layer 11: 0.89714515209198\n",
            "layer 12: 1.0\n",
            "layer 13: 0.8646920323371887\n",
            "\n",
            "Similarities of charge embedding in layer 13 with other layers:\n",
            "layer 1: 0.14583633840084076\n",
            "layer 2: 0.2830500602722168\n",
            "layer 3: 0.30904078483581543\n",
            "layer 4: 0.3568779230117798\n",
            "layer 5: 0.40904319286346436\n",
            "layer 6: 0.4602195620536804\n",
            "layer 7: 0.5151377320289612\n",
            "layer 8: 0.5630425214767456\n",
            "layer 9: 0.6000286340713501\n",
            "layer 10: 0.6614037752151489\n",
            "layer 11: 0.7576097249984741\n",
            "layer 12: 0.8646920323371887\n",
            "layer 13: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## similarity across sentences\n",
        "sim_across_sent = []\n",
        "for idx, embed in enumerate(charge_embeds_1):\n",
        "    cs = torch.nn.CosineSimilarity(dim=0)\n",
        "    print(f'Similarities of charge embedding of layer {idx+1} of first sentence with embeddings of second sentecne:')\n",
        "    sim = [cs(embed, emb).item() for emb in charge_embeds_2]\n",
        "    sim_across_sent.append(sim)\n",
        "    for index, sim in enumerate(sim):\n",
        "        print(f'layer {index+1}: {sim}')\n",
        "    print()"
      ],
      "metadata": {
        "id": "HQ2ATN5Yd6kk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "580c1f63-420d-44aa-a903-9de9f1ea5abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarities of charge embedding of layer 1 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.973694920539856\n",
            "layer 2: 0.7598669528961182\n",
            "layer 3: 0.6542379856109619\n",
            "layer 4: 0.5859935283660889\n",
            "layer 5: 0.5029579401016235\n",
            "layer 6: 0.4440789222717285\n",
            "layer 7: 0.3684220016002655\n",
            "layer 8: 0.3184411823749542\n",
            "layer 9: 0.241115540266037\n",
            "layer 10: 0.22136719524860382\n",
            "layer 11: 0.19748559594154358\n",
            "layer 12: 0.13913412392139435\n",
            "layer 13: 0.13586962223052979\n",
            "\n",
            "Similarities of charge embedding of layer 2 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.7696080207824707\n",
            "layer 2: 0.7493430376052856\n",
            "layer 3: 0.6617261171340942\n",
            "layer 4: 0.6002020239830017\n",
            "layer 5: 0.5346354246139526\n",
            "layer 6: 0.48375993967056274\n",
            "layer 7: 0.40533578395843506\n",
            "layer 8: 0.37032219767570496\n",
            "layer 9: 0.3025132119655609\n",
            "layer 10: 0.2806844115257263\n",
            "layer 11: 0.255287766456604\n",
            "layer 12: 0.22420768439769745\n",
            "layer 13: 0.19773077964782715\n",
            "\n",
            "Similarities of charge embedding of layer 3 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.6403536796569824\n",
            "layer 2: 0.6598193049430847\n",
            "layer 3: 0.6692901849746704\n",
            "layer 4: 0.5957030653953552\n",
            "layer 5: 0.5336570143699646\n",
            "layer 6: 0.49518024921417236\n",
            "layer 7: 0.42608165740966797\n",
            "layer 8: 0.4001524746417999\n",
            "layer 9: 0.32505011558532715\n",
            "layer 10: 0.3046550154685974\n",
            "layer 11: 0.2904015779495239\n",
            "layer 12: 0.27439627051353455\n",
            "layer 13: 0.21901442110538483\n",
            "\n",
            "Similarities of charge embedding of layer 4 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.5649772882461548\n",
            "layer 2: 0.5856820940971375\n",
            "layer 3: 0.6016457676887512\n",
            "layer 4: 0.5773099660873413\n",
            "layer 5: 0.5215698480606079\n",
            "layer 6: 0.4919624924659729\n",
            "layer 7: 0.43731945753097534\n",
            "layer 8: 0.417311429977417\n",
            "layer 9: 0.34674960374832153\n",
            "layer 10: 0.32340744137763977\n",
            "layer 11: 0.3059864044189453\n",
            "layer 12: 0.3019584119319916\n",
            "layer 13: 0.2518463134765625\n",
            "\n",
            "Similarities of charge embedding of layer 5 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.4569905400276184\n",
            "layer 2: 0.5000375509262085\n",
            "layer 3: 0.5191187858581543\n",
            "layer 4: 0.4989827275276184\n",
            "layer 5: 0.4842226505279541\n",
            "layer 6: 0.4581508934497833\n",
            "layer 7: 0.4040929079055786\n",
            "layer 8: 0.40415558218955994\n",
            "layer 9: 0.3421630561351776\n",
            "layer 10: 0.3261050879955292\n",
            "layer 11: 0.3134310841560364\n",
            "layer 12: 0.31029608845710754\n",
            "layer 13: 0.2664203345775604\n",
            "\n",
            "Similarities of charge embedding of layer 6 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.4232950210571289\n",
            "layer 2: 0.47433581948280334\n",
            "layer 3: 0.4931659996509552\n",
            "layer 4: 0.4684869050979614\n",
            "layer 5: 0.45989352464675903\n",
            "layer 6: 0.45741134881973267\n",
            "layer 7: 0.40840771794319153\n",
            "layer 8: 0.403299480676651\n",
            "layer 9: 0.3536955714225769\n",
            "layer 10: 0.3313145339488983\n",
            "layer 11: 0.31653618812561035\n",
            "layer 12: 0.309794157743454\n",
            "layer 13: 0.2610391080379486\n",
            "\n",
            "Similarities of charge embedding of layer 7 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.38650932908058167\n",
            "layer 2: 0.4303422272205353\n",
            "layer 3: 0.44204190373420715\n",
            "layer 4: 0.4140370488166809\n",
            "layer 5: 0.41924309730529785\n",
            "layer 6: 0.4239260256290436\n",
            "layer 7: 0.39174163341522217\n",
            "layer 8: 0.3894372582435608\n",
            "layer 9: 0.3454628884792328\n",
            "layer 10: 0.32173943519592285\n",
            "layer 11: 0.3066301941871643\n",
            "layer 12: 0.29678869247436523\n",
            "layer 13: 0.24611452221870422\n",
            "\n",
            "Similarities of charge embedding of layer 8 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.355349600315094\n",
            "layer 2: 0.40521425008773804\n",
            "layer 3: 0.4142926335334778\n",
            "layer 4: 0.3943411707878113\n",
            "layer 5: 0.4060644209384918\n",
            "layer 6: 0.4141016900539398\n",
            "layer 7: 0.3903631567955017\n",
            "layer 8: 0.3996470868587494\n",
            "layer 9: 0.3568446636199951\n",
            "layer 10: 0.3384961187839508\n",
            "layer 11: 0.3234296441078186\n",
            "layer 12: 0.31213799118995667\n",
            "layer 13: 0.2622218430042267\n",
            "\n",
            "Similarities of charge embedding of layer 9 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.30314624309539795\n",
            "layer 2: 0.3488141894340515\n",
            "layer 3: 0.3562793731689453\n",
            "layer 4: 0.339025616645813\n",
            "layer 5: 0.35046568512916565\n",
            "layer 6: 0.36540260910987854\n",
            "layer 7: 0.35931771993637085\n",
            "layer 8: 0.3748297393321991\n",
            "layer 9: 0.3381803333759308\n",
            "layer 10: 0.3219410479068756\n",
            "layer 11: 0.31516262888908386\n",
            "layer 12: 0.3007276952266693\n",
            "layer 13: 0.2573518753051758\n",
            "\n",
            "Similarities of charge embedding of layer 10 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.2591025233268738\n",
            "layer 2: 0.3147982358932495\n",
            "layer 3: 0.32559317350387573\n",
            "layer 4: 0.31186237931251526\n",
            "layer 5: 0.3369181454181671\n",
            "layer 6: 0.3645378649234772\n",
            "layer 7: 0.36116254329681396\n",
            "layer 8: 0.3766242265701294\n",
            "layer 9: 0.3427303433418274\n",
            "layer 10: 0.33818525075912476\n",
            "layer 11: 0.33763036131858826\n",
            "layer 12: 0.3236938416957855\n",
            "layer 13: 0.2699034810066223\n",
            "\n",
            "Similarities of charge embedding of layer 11 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.22353839874267578\n",
            "layer 2: 0.28582069277763367\n",
            "layer 3: 0.3046623170375824\n",
            "layer 4: 0.29113367199897766\n",
            "layer 5: 0.3183327615261078\n",
            "layer 6: 0.3513559103012085\n",
            "layer 7: 0.34482306241989136\n",
            "layer 8: 0.36142390966415405\n",
            "layer 9: 0.33647391200065613\n",
            "layer 10: 0.3251429796218872\n",
            "layer 11: 0.3665906488895416\n",
            "layer 12: 0.368426114320755\n",
            "layer 13: 0.3095683455467224\n",
            "\n",
            "Similarities of charge embedding of layer 12 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.19693946838378906\n",
            "layer 2: 0.2743978202342987\n",
            "layer 3: 0.2998124659061432\n",
            "layer 4: 0.286724716424942\n",
            "layer 5: 0.31970322132110596\n",
            "layer 6: 0.35631096363067627\n",
            "layer 7: 0.3484906852245331\n",
            "layer 8: 0.36382099986076355\n",
            "layer 9: 0.33337703347206116\n",
            "layer 10: 0.3151668608188629\n",
            "layer 11: 0.3724960386753082\n",
            "layer 12: 0.42603981494903564\n",
            "layer 13: 0.37094447016716003\n",
            "\n",
            "Similarities of charge embedding of layer 13 of first sentence with embeddings of second sentecne:\n",
            "layer 1: 0.18182706832885742\n",
            "layer 2: 0.2221238911151886\n",
            "layer 3: 0.2240372896194458\n",
            "layer 4: 0.1968778371810913\n",
            "layer 5: 0.22365276515483856\n",
            "layer 6: 0.243643119931221\n",
            "layer 7: 0.22935239970684052\n",
            "layer 8: 0.25682419538497925\n",
            "layer 9: 0.2151634246110916\n",
            "layer 10: 0.21411147713661194\n",
            "layer 11: 0.2714461386203766\n",
            "layer 12: 0.30264216661453247\n",
            "layer 13: 0.3703170418739319\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a few sentences about your results and how `BERT` captures the contextual meaning of words.\n",
        "\n"
      ],
      "metadata": {
        "id": "-f_4s-_c8DI1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzYP8ShGO7Fv"
      },
      "source": [
        "***WRITE YOUR ANSWER HERE***\n",
        "\n",
        "**Similarities between Close Layers:**\n",
        "\n",
        "Embeddings from nearby layers in BERT tend to exhibit higher cosine similarities. Think of it like layers working together step-by-step. Layer 5, for example, builds upon the understanding developed in layer 4 and refines it further based on the context. This incremental approach leads to higher similarities between embeddings from consecutive layers as they process similar contextual information.\n",
        "\n",
        "**Capturing Deeper Concepts with Depth:**\n",
        "\n",
        "As we move towards deeper layers, the focus shifts towards capturing more abstract and sentence-specific meaning. These deeper layers integrate information from previous layers and the entire sentence, resulting in embeddings that might be less similar to those from earlier stages. This reflects BERT's ability to dynamically adjust its understanding of a word based on the complete sentence context.\n",
        "\n",
        "**Similarities Across Sentences:**\n",
        "\n",
        "Interestingly, early layers processing the same word in different sentences might show higher similarities compared to deeper layers. This can be attributed to the initial stages focusing on the word's base meaning or a more general interpretation. However, as the model progresses through deeper layers and encounters more context, sentence-specific details become more prominent. This can lead to potentially greater divergence between embeddings for the same word used in different contexts.\n",
        "\n",
        "**How `BERT` captures the contextual meaning of words?**\n",
        "\n",
        "Masked Language Modeling (MLM) and attention mechanism help BERT to capture the contexual meaning of words. In the MLM, when a token is masked, the model should predict the masked token based on other tokens. Other token will help the model to understand the context of masked token and predict it correctly.\n",
        "BERT has transformer as its buliding block that utilize attention mechanism. This mechanism will the model to focus on the parts of a sentence that reveal the context of a certain word and stacking multiple transformers with this method help us to capture more complex patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.4 (10 points)\n",
        "In this part, we will use `BERT` for masked word completion task. Run the following cell to download the pretrained BERT base model (cased)."
      ],
      "metadata": {
        "id": "2bI3GUhR8Ydu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "_G7eW-n_8khd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acdb9120-141d-4a02-cc03-7cca45044ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's challenge `BERT`'s knowledge about named entities. Consider the following sentences\n",
        "- **William Shakespeare**, widely regarded as the greatest writer in the English language, was born in Stratford-upon-Avon, England, in 1564.\n",
        "- The Amazon Rainforest, spanning across nine countries in **South America**,\n",
        "is the largest tropical rainforest on Earth, covering an area of over 6.7\n",
        "million square kilometers (2.7 million square miles) and harboring\n",
        "unparalleled biodiversity.\n",
        "- The Statue of Liberty, a gift from **France** to the United States, was dedicated\n",
        "on October 28, 1886. Standing on Liberty Island in New York Harbor, it\n",
        "symbolizes freedom and democracy and has become a universal symbol of hope and\n",
        "opportunity.\n",
        "\n",
        "Replace the bold words with the mask token (if they are more than one token, put as many as needed). Write down the top 5 choices of BERT for the mask tokens. In this part, you should use `token_logits`.\n",
        "\n",
        "*Hints*\n",
        "\n",
        "- Use `torch.where` to find the index of a masked token within the input tensor (note that `tokenizer.mask_token_id` gives us the index of the mask token in the vocabulary).\n",
        "- Use `torch.topk` to get the k largest elements of a given tensor along a given dimension.\n",
        "- Use `tokenizer.decode([token_id])` to convert a single integer `token_id` to a token string."
      ],
      "metadata": {
        "id": "sJUwtMHE8nOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prediction function\n",
        "def predict_masked_tokens(sentences):\n",
        "    for sentence in sentences:\n",
        "       # Tokenize the input sentence\n",
        "       tokenized_text = tokenizer.tokenize(sentence)\n",
        "       # Find the indices of masked tokens\n",
        "       masked_indices = [i for i, token in enumerate(tokenized_text) if token == \"[MASK]\"]\n",
        "\n",
        "       # Predict for each masked token\n",
        "       for masked_index in masked_indices:\n",
        "           inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "           outputs = model(**inputs)\n",
        "           predictions = outputs[0]\n",
        "           probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
        "           top_k_weights, top_k_indices = torch.topk(probs, 5, sorted=True)\n",
        "\n",
        "           print(f\"**Predictions for sentence: {sentence}**\")\n",
        "           print(f\"Masked token at index: {masked_index}\")\n",
        "           for i, pred_idx in enumerate(top_k_indices):\n",
        "               predicted_token = tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
        "               token_weight = top_k_weights[i]\n",
        "               print(f\"[{i+1}] {predicted_token} | weights: {float(token_weight):.4f}\")\n",
        "           print()\n",
        "\n",
        "# Sentences for prediction\n",
        "sentences = [\n",
        "    \" [MASK] [MASK], widely regarded as the greatest writer in the English language, was born in Stratford-upon-Avon, England, in 1564.\",\n",
        "    \"The Amazon Rainforest, spanning across nine countries in [MASK] [MASK], is the largest tropical rainforest on Earth, covering an area of over 6.7 million square kilometers (2.7 million square miles) and harboring unparalleled biodiversity.\",\n",
        "    \"The Statue of Liberty, a gift from [MASK] to the United States, was dedicated on October 28, 1886. Standing on Liberty Island in New York Harbor, it symbolizes freedom and democracy and has become a universal symbol of hope and opportunity.\"\n",
        "]\n",
        "\n",
        "# Perform predictions\n",
        "predict_masked_tokens(sentences)\n"
      ],
      "metadata": {
        "id": "_03N5Ie58oFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411150f2-7c75-4433-879f-9fe8b67b7ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Predictions for sentence:  [MASK] [MASK], widely regarded as the greatest writer in the English language, was born in Stratford-upon-Avon, England, in 1564.**\n",
            "Masked token at index: 0\n",
            "[1] . | weights: 0.0258\n",
            "[2] the | weights: 0.0140\n",
            "[3] , | weights: 0.0117\n",
            "[4] ) | weights: 0.0102\n",
            "[5] of | weights: 0.0060\n",
            "\n",
            "**Predictions for sentence:  [MASK] [MASK], widely regarded as the greatest writer in the English language, was born in Stratford-upon-Avon, England, in 1564.**\n",
            "Masked token at index: 1\n",
            "[1] thomas | weights: 0.3534\n",
            "[2] william | weights: 0.1020\n",
            "[3] edmund | weights: 0.0824\n",
            "[4] samuel | weights: 0.0649\n",
            "[5] henry | weights: 0.0538\n",
            "\n",
            "**Predictions for sentence: The Amazon Rainforest, spanning across nine countries in [MASK] [MASK], is the largest tropical rainforest on Earth, covering an area of over 6.7 million square kilometers (2.7 million square miles) and harboring unparalleled biodiversity.**\n",
            "Masked token at index: 9\n",
            "[1] in | weights: 0.9956\n",
            "[2] of | weights: 0.0029\n",
            "[3] within | weights: 0.0004\n",
            "[4] across | weights: 0.0002\n",
            "[5] and | weights: 0.0001\n",
            "\n",
            "**Predictions for sentence: The Amazon Rainforest, spanning across nine countries in [MASK] [MASK], is the largest tropical rainforest on Earth, covering an area of over 6.7 million square kilometers (2.7 million square miles) and harboring unparalleled biodiversity.**\n",
            "Masked token at index: 10\n",
            "[1] the | weights: 0.5348\n",
            "[2] africa | weights: 0.0500\n",
            "[3] asia | weights: 0.0468\n",
            "[4] global | weights: 0.0286\n",
            "[5] modern | weights: 0.0262\n",
            "\n",
            "**Predictions for sentence: The Statue of Liberty, a gift from [MASK] to the United States, was dedicated on October 28, 1886. Standing on Liberty Island in New York Harbor, it symbolizes freedom and democracy and has become a universal symbol of hope and opportunity.**\n",
            "Masked token at index: 8\n",
            "[1] from | weights: 0.8312\n",
            "[2] of | weights: 0.0699\n",
            "[3] that | weights: 0.0197\n",
            "[4] by | weights: 0.0123\n",
            "[5] the | weights: 0.0106\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a few sentences about your results and how masked language modeling works."
      ],
      "metadata": {
        "id": "dQ1x5vcH8pu1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niH2-d-4OuX5"
      },
      "source": [
        "***WRITE YOUR ANSWER HERE***\n",
        "\n",
        "In the first sentence, particularly with regard to the first token, it's evident that the model encounters difficulty in predicting the initial token, as indicated by the low probabilities assigned. It seems to favor the more probable token without substantial contextual guidance, possibly due to the lack of sufficient surrounding context. However, concerning the second masked token, the model appropriately identifies the necessity for a proper noun, albeit assigning a lower probability to the correct answer, \"William.\"\n",
        "\n",
        "In the second sentence, the model assigns a high probability to \"in\" for the first masked token, a choice consistent with the preceding context of \"spanning across nine countries,\" suggesting an expectation for a preposition. Regarding the second token, the appearance of \"Africa\" and \"Asia\" among the predictions indicates the model's correct understanding of the need for a continental name.\n",
        "\n",
        "In the third sentence, once again, the top predictions primarily consist of prepositions, despite the requirement for a noun. This tendency may stem from the model's interpretation of \"a gift\" and \"to the United States,\" leading it to anticipate the necessity of a prepositional phrase.\n",
        "\n",
        "**How masked language modeling works?**\n",
        "\n",
        "Masked Language Modeling (MLM) is a technique where some words in a sentence are masked, or hidden, and the model must predict the correct word to replace the masked one. This helps the model understand the context and meaning of words in a sentence. It's used in training models like BERT to improve language understanding. The model will be trained on huge volumes of text data so that it can learn to recognize word context and forecast masked tokens depending on their context. After predicting a masked token, we will compute loss and backpropagate and the model will gradually learn to predict the correct word for the masked token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez253CdmAMd7"
      },
      "source": [
        "# Part 2: Transfer Learning with BERT (60 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='RED' size='+3'>NEW</font>\n",
        "\n",
        "## Adding a hardware accelerator\n",
        "\n",
        "Please go to the menu and add a GPU as follows:\n",
        "\n",
        "`Edit > Notebook Settings > Hardware accelerator > (GPU)`\n",
        "\n",
        "Run the following cell to confirm that the GPU is detected."
      ],
      "metadata": {
        "id": "1YYPbqm01emB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Confirm that the GPU is detected\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = torch.cuda.get_device_name()\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")"
      ],
      "metadata": {
        "id": "sJAR9u-d2Ibc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51721ede-767f-4c20-dc83-c4f98c4200f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found device: Tesla T4, n_gpu: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='RED' size='+3'>NEW</font>\n",
        "\n",
        "## Installing Hugging Face's Transformers library\n",
        "We will use Hugging Face's Transformers (https://github.com/huggingface/transformers), an open-source library that provides general-purpose architectures for natural language understanding and generation with a collection of various pretrained models made by the NLP community. This library will allow us to easily use pretrained models like `BERT` and perform experiments on top of them. We can use these models to solve downstream target tasks, such as text classification, question answering, and sequence labeling.\n",
        "\n",
        "Run the following cell to install Hugging Face's Transformers library, download data and supporting code for the homework, and install some additional packages. Note that you will be asked to link with your Google Drive account to download some of these files."
      ],
      "metadata": {
        "id": "Nq3p2cTF2Ndd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/accelerate\n",
        "!pip install transformers\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "print('success!')\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "data_file = drive.CreateFile({'id': '1zeo8FcaNUnhN660mGMNEAPvxOE4DPOnE'})\n",
        "data_file.GetContentFile('hw1.zip')\n",
        "\n",
        "# Extract data from the zipfile and put it into the current directory\n",
        "with zipfile.ZipFile('hw1.zip', 'r') as zip_file:\n",
        "    zip_file.extractall('./')\n",
        "os.remove('hw1.zip')\n",
        "# We will use hw1 as our working directory\n",
        "os.chdir('hw1')\n",
        "print(\"Data and supporting code downloaded!\")\n",
        "\n",
        "pretrained_models_dir = './pretrained_models_dir'\n",
        "if not os.path.isdir(pretrained_models_dir):\n",
        "  os.mkdir(pretrained_models_dir)   # directory to save pretrained models\n",
        "print('model directory created')\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "print('everything set up!')"
      ],
      "metadata": {
        "id": "aDU0CpNM2Xfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda5e1b9-e25c-44b4-c1df-12d8e22ac5ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/accelerate\n",
            "  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-kmtzu47_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-kmtzu47_\n",
            "  Resolved https://github.com/huggingface/accelerate to commit d927b8f3a2ee811a60dbd83d8f12193512b73fc3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.0.dev0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.0.dev0) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.0.dev0) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub<0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.0.dev0) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.0.dev0) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.0.dev0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.29.0.dev0) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.29.0.dev0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.21.0->accelerate==0.29.0.dev0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.29.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "success!\n",
            "Data and supporting code downloaded!\n",
            "model directory created\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: conllu in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.5.3)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (3.0.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.0.9)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->-r requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans->-r requirements.txt (line 3)) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (2024.2.2)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (2024.4.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans->-r requirements.txt (line 3)) (3.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 1)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 1)) (3.4.0)\n",
            "everything set up!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the advent of methods such as `BERT` [(Devlin et al., 2019)](https://arxiv.org/pdf/1810.04805.pdf), the dominant paradigm for developing NLP models has shifted to transfer learning: first, pretrain a large language model on large amounts of unlabeled data, and then fine-tune the resulting model on the downstream target task. In this section, we will use `BERT` to solve downstream target tasks across several classes of problems, including classification, question answering, and sequence labeling."
      ],
      "metadata": {
        "id": "1dyG8xSuMxFm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_ZM8bTI-HNP"
      },
      "source": [
        "### Question 2.1 (25 points)\n",
        "Before diving into the practical applications, let's first ensure your foundational knowledge is solid. Please answer the following questions briefly, aiming for two or three sentences each. This exercise is designed to prime your understanding of the transformative technologies we're exploring, and making sure you're well-prepared for the hands-on challenges ahead.\n",
        "\n",
        "\n",
        "**A) Describe the role of the attention mechanism within BERT. How does the multi-head attention mechanism enable BERT to process different parts of the input data simultaneously, and why is this beneficial for natural language understanding tasks?**\n",
        "\n",
        "**B) Describe how BERT's bidirectionality is different from traditional sequential language models.**\n",
        "\n",
        "**C) What is segment embedding's functionality in BERT?**\n",
        "\n",
        "**D) Briefly describe one variant of BERT (e.g., RoBERTa, ALBERT, DistilBERT) and highlight a key difference in its approach or architecture compared to the original BERT model.**\n",
        "\n",
        "**E) Despite its success, BERT has limitations. Can you identify one limitation or challenge associated with using BERT for NLP tasks?**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***WRITE YOUR ANSWER HERE IN A FEW SENTENCES FOR EACH SECTION***\n",
        "\n",
        "**A)** BERT's attention mechanism plays a crucial role in its ability to understand the relationships between words in a sentence. It allows the model to focus on different words in the input sequence when producing an output. The multi-head attention mechanism enables BERT to process different parts of the input data simultaneously by splitting the input into multiple heads, each learning a different representation of the data. It performs attention calculations from multiple perspectives simultaneously. Each \"head\" learns different attention patterns, allowing the model to capture diverse contextual relationships between words. This is beneficial for natural language understanding tasks as it helps the model capture a more comprehensive understanding of the input by considering various contexts and relationships between words.\n",
        "\n",
        "**B)** Traditional sequential language models process input data in a sequential manner (Left to Right), with each output depending on the previous input. In contrast, BERT uses a bidirectional approach (Left to Right, Right to Left), where the model processes the input data in both directions simultaneously. This means that BERT can consider both the preceding and following words in the input sequence when generating an output, allowing it to capture a more nuanced understanding of the input data and better handle complex language tasks.\n",
        "\n",
        "**C)** In BERT, segment embeddings are used to differentiate between two types of input sequences, such as two sentences in a sentence-pair task. The segment embeddings are added to the token embeddings, which represent the individual words in the input sequence. This allows BERT to distinguish between the two input sequences and process them separately, even though they are combined into a single input sequence. By using segment embeddings, BERT can handle various natural language understanding tasks, such as question-answering and natural language inference, where it is important to differentiate between the input sequences.\n",
        "\n",
        "**D)** RoBERTa is a variant of BERT that was developed to improve the performance of the original BERT model. These are key differences between two models:\n",
        "\n",
        "* RoBERTa trains on a massive dataset of text, compared to BERT. This allows it to develop a richer and more detailed understanding of language.\n",
        "* Unlike BERT's static masking, RoBERTa uses a dynamic approach. It hides different words in each training example, forcing it to learn from a wider variety of contexts.\n",
        "* RoBERTa skips the \"next sentence prediction\" step used during BERT's training. This allows it to concentrate solely on understanding masked words, leading to a more versatile language representation.\n",
        "* RoBERTa utilizes a larger vocabulary. This enables it to capture the finer details of language compared to BERT.\n",
        "* RoBERTa undergoes a more intensive fine-tuning process compared to BERT. This involves longer training periods and adjustments to learning rates. This allows RoBERTa to adapt more effectively to specific natural language processing tasks.\n",
        "\n",
        "**E)**\n",
        "\n",
        "\n",
        "BERT has a large model size that will cause computational issues:\n",
        "*   **Memory Requirements**: Running BERT models can require a large amount of memory, especially for models with a high number of parameters. This can limit its deployment on devices with limited memory, like mobile phones or embedded systems.\n",
        "\n",
        "* **Inference Speed**: Making predictions with a pre-trained BERT model can be computationally expensive. This can be an issue for tasks requiring real-time responses, such as chatbots or voice assistants.\n",
        "\n"
      ],
      "metadata": {
        "id": "OVJL9B73ASsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After answering the above questions, let's run the cell below to import necessary packages and set some things up for fine-tuning `BERT`."
      ],
      "metadata": {
        "id": "TpqiH9gP2x4N"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kDEdMvq9tCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3199c97e-1de0-4e81-e441-3719918b231f"
      },
      "source": [
        "# coding=utf-8\n",
        "\n",
        "import dataclasses\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import timeit\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Callable, Dict, List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelWithLMHead,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModelForQuestionAnswering,\n",
        "    AutoModelForTokenClassification,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedTokenizer,\n",
        "    EvalPrediction\n",
        ")\n",
        "from transformers import (\n",
        "    GlueDataset,\n",
        "    SquadDataset,\n",
        "    LineByLineTextDataset,\n",
        "    TextDataset,\n",
        "    DataCollatorForLanguageModeling,\n",
        ")\n",
        "from transformers import GlueDataTrainingArguments, SquadDataTrainingArguments\n",
        "from transformers import (\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    glue_compute_metrics,\n",
        "    glue_output_modes,\n",
        "    glue_tasks_num_labels,\n",
        "    set_seed,\n",
        ")\n",
        "from transformers.data.processors.squad import SquadResult\n",
        "from transformers.data.metrics.squad_metrics import (\n",
        "    compute_predictions_logits,\n",
        "    squad_evaluate,\n",
        ")\n",
        "from tasks import NER\n",
        "from utils_ner import Split, TokenClassificationDataset, TokenClassificationTask\n",
        "\n",
        "from transformers import glue_processors\n",
        "from transformers.data.processors.utils import InputExample\n",
        "from langdetect import detect\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModelArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
        "    \"\"\"\n",
        "    model_type: str = field(\n",
        "        default=\"bert\",\n",
        "        metadata={\"help\": \"Model type, e.g., bert.\"}\n",
        "    )\n",
        "    model_name_or_path: str = field(\n",
        "        default=\"bert\",\n",
        "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models.\"}\n",
        "    )\n",
        "    do_lower_case: Optional[bool] = field(\n",
        "        default=False,\n",
        "        metadata={\"help\": \"Whether you want to do lower case on input before tokenization.\"}\n",
        "    )\n",
        "    model_cache_dir: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Where you want to store the pretrained models downloaded from s3.\"}\n",
        "    )\n",
        "    data_cache_dir: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Where you want to store the cached features for the task.\"}\n",
        "    )\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class NerDataTrainingArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
        "    \"\"\"\n",
        "\n",
        "    data_dir: str = field(\n",
        "        metadata={\"help\": \"The input data dir. Should contain data files for the task.\"}\n",
        "    )\n",
        "    labels: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Path to a file containing all labels for the task.\"},\n",
        "    )\n",
        "    max_seq_length: int = field(\n",
        "        default=128,\n",
        "        metadata={\n",
        "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "            \"than this will be truncated, sequences shorter will be padded.\"\n",
        "        },\n",
        "    )\n",
        "    overwrite_cache: bool = field(\n",
        "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets.\"}\n",
        "    )\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LMDataTrainingArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
        "    \"\"\"\n",
        "\n",
        "    train_data_file: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"The input training data file (a text file).\"}\n",
        "    )\n",
        "    eval_data_file: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"An optional input evaluation data file to evaluate the perplexity on (a text file).\"},\n",
        "    )\n",
        "    line_by_line: bool = field(\n",
        "        default=False,\n",
        "        metadata={\"help\": \"Whether distinct lines of text in the dataset are to be handled as distinct sequences.\"},\n",
        "    )\n",
        "\n",
        "    mlm: bool = field(\n",
        "        default=False, metadata={\"help\": \"Train with masked-language modeling loss instead of language modeling.\"}\n",
        "    )\n",
        "    mlm_probability: float = field(\n",
        "        default=0.15, metadata={\"help\": \"Ratio of tokens to mask for masked language modeling loss\"}\n",
        "    )\n",
        "    block_size: int = field(\n",
        "        default=-1,\n",
        "        metadata={\n",
        "            \"help\": \"Optional input sequence length after tokenization.\"\n",
        "            \"The training dataset will be truncated in block of this size for training.\"\n",
        "            \"Default to the model max input length for single sentence inputs (take into account special tokens).\"\n",
        "        },\n",
        "    )\n",
        "    overwrite_cache: bool = field(\n",
        "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
        "    )\n",
        "\n",
        "\n",
        "def get_dataset(\n",
        "    args: LMDataTrainingArguments,\n",
        "    tokenizer: PreTrainedTokenizer,\n",
        "    evaluate: bool = False,\n",
        "    cache_dir: Optional[str] = None,\n",
        "):\n",
        "    file_path = args.eval_data_file if evaluate else args.train_data_file\n",
        "    if args.line_by_line:\n",
        "        return LineByLineTextDataset(tokenizer=tokenizer, file_path=file_path, block_size=args.block_size)\n",
        "    else:\n",
        "        return TextDataset(\n",
        "            tokenizer=tokenizer,\n",
        "            file_path=file_path,\n",
        "            block_size=args.block_size,\n",
        "            overwrite_cache=args.overwrite_cache,\n",
        "            cache_dir=cache_dir,\n",
        "        )\n",
        "\n",
        "\n",
        "DATA_TRAINING_ARGUMENTS = {\n",
        "    \"text_classification\": GlueDataTrainingArguments,\n",
        "    \"question_answering\": SquadDataTrainingArguments,\n",
        "    \"sequence_labeling\": NerDataTrainingArguments,\n",
        "}\n",
        "\n",
        "\n",
        "AUTO_MODEL = {\n",
        "    \"text_classification\": AutoModelForSequenceClassification,\n",
        "    \"question_answering\": AutoModelForQuestionAnswering,\n",
        "    \"sequence_labeling\": AutoModelForTokenClassification,\n",
        "}\n",
        "\n",
        "\n",
        "DATASET = {\n",
        "    \"text_classification\": GlueDataset,\n",
        "    \"question_answering\": SquadDataset,\n",
        "    \"sequence_labeling\": TokenClassificationDataset,\n",
        "}\n",
        "\n",
        "\n",
        "# some functions for fine-tuning BERT on a downstream target task\n",
        "def do_target_task_finetuning(model_name_or_path, task_type, output_dir, **kwargs):\n",
        "    r\"\"\" Fine-tuning BERT on a downstream target task.\n",
        "    Params:\n",
        "        **model_name_or_path**: either:\n",
        "            - a string with the `shortcut name` of a pre-trained model configuration to load from cache\n",
        "                or download and cache if not already stored in cache (e.g. 'bert-base-uncased').\n",
        "            - a path to a `directory` containing a configuration file saved\n",
        "                using the `save_pretrained(save_directory)` method.\n",
        "            - a path or url to a saved configuration `file`.\n",
        "        **task_type**: string:\n",
        "            The class of the task to train, selected in\n",
        "            [\"text_classification\", \"question_answering\", \"sequence_labeling\"].\n",
        "        **output_dir**: string:\n",
        "            The output directory where the model predictions and checkpoints will be written.\n",
        "        **kwargs**: (`optional`) dict:\n",
        "            Dictionary of key/value pairs with which to update the configuration object after loading.\n",
        "            - The values in kwargs of any keys which are configuration attributes will be used\n",
        "            to override the loaded values.\n",
        "    \"\"\"\n",
        "    # See all possible arguments in src/transformers/training_args.py\n",
        "\n",
        "    assert task_type in DATA_TRAINING_ARGUMENTS\n",
        "    model_args = ModelArguments(model_name_or_path=model_name_or_path)\n",
        "    data_args_params = {}\n",
        "    for param in [\"task_name\", \"data_dir\"]:\n",
        "        if param in kwargs:\n",
        "            data_args_params.update({param: kwargs[param]})\n",
        "\n",
        "    data_args = DATA_TRAINING_ARGUMENTS[task_type](**data_args_params)\n",
        "    training_args = TrainingArguments(output_dir=output_dir)\n",
        "\n",
        "    # override the loaded configs\n",
        "    configs = (model_args, data_args, training_args)\n",
        "    for config in configs:\n",
        "        for key, value in kwargs.items():\n",
        "            if hasattr(config, key):\n",
        "                setattr(config, key, value)\n",
        "\n",
        "    if (\n",
        "        os.path.exists(training_args.output_dir)\n",
        "        and os.listdir(training_args.output_dir)\n",
        "        and training_args.do_train\n",
        "        and not training_args.overwrite_output_dir\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
        "            f\"Use --overwrite_output_dir to overcome.\"\n",
        "        )\n",
        "\n",
        "    for p in [model_args.model_cache_dir, model_args.data_cache_dir, training_args.output_dir]:\n",
        "        if not os.path.exists(p):\n",
        "            os.makedirs(p)\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO,\n",
        "    )\n",
        "\n",
        "    logger.info(\"Process device: %s, n_gpu: %s\", training_args.device, training_args.n_gpu)\n",
        "    logger.info(\"Training/evaluation parameters %s\", training_args)\n",
        "\n",
        "\n",
        "    # Set seed\n",
        "    set_seed(training_args.seed)\n",
        "\n",
        "    if task_type == \"text_classification\":\n",
        "        try:\n",
        "            data_args.task_name = data_args.task_name.lower()\n",
        "            num_labels = glue_tasks_num_labels[data_args.task_name]\n",
        "            output_mode = glue_output_modes[data_args.task_name]\n",
        "        except KeyError:\n",
        "            raise ValueError(\"Task not found: %s\" % (data_args.task_name))\n",
        "    elif task_type == \"sequence_labeling\":\n",
        "        token_classification_task = NER() # You might want to this to Chunk() or POS()\n",
        "        # if you are working with a Chunk or POS task, respectively\n",
        "        labels = token_classification_task.get_labels(data_args.labels)\n",
        "        label_map: Dict[int, str] = {i: label for i, label in enumerate(labels)}\n",
        "        num_labels = len(labels)\n",
        "\n",
        "    # Load pretrained model and tokenizer\n",
        "\n",
        "    AutoModel = AUTO_MODEL[task_type]\n",
        "    auto_config_params = {\n",
        "        'pretrained_model_name_or_path': model_args.model_name_or_path,\n",
        "        'cache_dir': model_args.model_cache_dir,\n",
        "    }\n",
        "\n",
        "    if task_type == \"text_classification\":\n",
        "        auto_config_params.update({\n",
        "            \"num_labels\": num_labels,\n",
        "            \"finetuning_task\": data_args.task_name,\n",
        "        })\n",
        "    elif task_type == \"sequence_labeling\":\n",
        "        auto_config_params.update({\n",
        "            \"num_labels\": num_labels,\n",
        "            \"id2label\": label_map,\n",
        "            \"label2id\": {label: i for i, label in enumerate(labels)},\n",
        "        })\n",
        "\n",
        "    config = AutoConfig.from_pretrained(**auto_config_params)\n",
        "\n",
        "    auto_tokenizer_params = {\n",
        "        \"pretrained_model_name_or_path\": model_args.model_name_or_path,\n",
        "        \"cache_dir\": model_args.model_cache_dir,\n",
        "        \"do_lower_case\": model_args.do_lower_case,\n",
        "    }\n",
        "    tokenizer = AutoTokenizer.from_pretrained(**auto_tokenizer_params)\n",
        "\n",
        "    auto_model_params = {\n",
        "        \"pretrained_model_name_or_path\": model_args.model_name_or_path,\n",
        "        \"from_tf\": False,\n",
        "        \"config\": config,\n",
        "        \"cache_dir\": model_args.model_cache_dir,\n",
        "    }\n",
        "\n",
        "    if \"model_load_mode\" in kwargs and kwargs[\"model_load_mode\"] == \"base_model_only\":\n",
        "        WEIGHTS_NAME = \"pytorch_model.bin\"\n",
        "        archive_file = os.path.join(model_args.model_name_or_path, WEIGHTS_NAME)\n",
        "        # Use torch.load with map_location=torch.device() to map the pretrained model to our device.\n",
        "        model_state_dict = torch.load(archive_file, map_location=torch.device(training_args.device))\n",
        "\n",
        "        state_dict_with_prefix = {}\n",
        "        for key, value in model_state_dict.items():\n",
        "            if key.startswith(model_args.model_type):\n",
        "                state_dict_with_prefix[key] = value\n",
        "\n",
        "        auto_model_params.update({\"state_dict\": state_dict_with_prefix})\n",
        "\n",
        "    model = AutoModel.from_pretrained(**auto_model_params)\n",
        "\n",
        "    # Get datasets\n",
        "    Dataset = DATASET[task_type]\n",
        "    dataset_params = {\n",
        "        \"tokenizer\": tokenizer,\n",
        "    }\n",
        "    if task_type == \"sequence_labeling\":\n",
        "        dataset_params.update({\n",
        "            \"token_classification_task\": token_classification_task,\n",
        "            \"data_dir\": data_args.data_dir,\n",
        "            \"labels\": labels,\n",
        "            \"model_type\": model_args.model_type,\n",
        "            \"max_seq_length\": data_args.max_seq_length\n",
        "        })\n",
        "\n",
        "    else:\n",
        "        dataset_params.update({\n",
        "            \"args\": data_args,\n",
        "            \"cache_dir\": model_args.data_cache_dir,\n",
        "        })\n",
        "\n",
        "    train_dataset = (Dataset(**dataset_params) if training_args.do_train else None)\n",
        "\n",
        "    dataset_params.update({\"mode\": Split.dev if task_type == \"sequence_labeling\" else \"dev\"})\n",
        "    eval_dataset = (Dataset(**dataset_params) if training_args.do_eval else None)\n",
        "\n",
        "    # Initialize our Trainer\n",
        "    trainer_params = {\n",
        "        \"model\": model,\n",
        "        \"args\": training_args,\n",
        "        \"train_dataset\": train_dataset,\n",
        "        \"eval_dataset\": eval_dataset,\n",
        "    }\n",
        "    trainer = Trainer(**trainer_params)\n",
        "\n",
        "    # Training\n",
        "    if training_args.do_train:\n",
        "        trainer.train(\n",
        "            model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\n",
        "        )\n",
        "        trainer.save_model()\n",
        "        # For convenience, we also re-save the tokenizer to the same directory\n",
        "        tokenizer.save_pretrained(training_args.output_dir)\n",
        "\n",
        "    # Evaluation\n",
        "    eval_results = {}\n",
        "    if training_args.do_eval:\n",
        "        if task_type == \"text_classification\":\n",
        "            def build_compute_metrics_fn(task_name: str) -> Callable[[EvalPrediction], Dict]:\n",
        "                def compute_metrics_fn(p: EvalPrediction):\n",
        "                    if output_mode == \"classification\":\n",
        "                        preds = np.argmax(p.predictions, axis=1)\n",
        "                    elif output_mode == \"regression\":\n",
        "                        preds = np.squeeze(p.predictions)\n",
        "                    return glue_compute_metrics(task_name, preds, p.label_ids)\n",
        "                return compute_metrics_fn\n",
        "\n",
        "            logger.info(\"*** Evaluate ***\")\n",
        "            # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "            eval_datasets = [eval_dataset]\n",
        "            if data_args.task_name == \"mnli\":\n",
        "                mnli_mm_data_args = dataclasses.replace(data_args, task_name=\"mnli-mm\")\n",
        "                eval_datasets.append(\n",
        "                    Dataset(mnli_mm_data_args, tokenizer=tokenizer, mode=\"dev\", cache_dir=model_args.data_cache_dir)\n",
        "                )\n",
        "\n",
        "            for eval_dataset in eval_datasets:\n",
        "                trainer.compute_metrics = build_compute_metrics_fn(eval_dataset.args.task_name)\n",
        "                eval_result = trainer.evaluate(eval_dataset=eval_dataset)\n",
        "\n",
        "                output_eval_file = os.path.join(training_args.output_dir, f\"eval_results.txt\")\n",
        "                with open(output_eval_file, \"w\") as writer:\n",
        "                    logger.info(\"***** Eval results *****\")\n",
        "                    for key, value in eval_result.items():\n",
        "                        logger.info(\"  %s = %s\", key, value)\n",
        "                        writer.write(\"%s = %s\\n\" % (key, value))\n",
        "\n",
        "                eval_results.update(eval_result)\n",
        "\n",
        "        elif task_type == \"question_answering\":\n",
        "            # We don't use trainer.evaluate here since it currently does not support question answering tasks\n",
        "            # (https://github.com/huggingface/transformers/issues/7032)\n",
        "            model = AutoModel.from_pretrained(model_args.model_cache_dir)\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_args.model_cache_dir, do_lower_case=model_args.do_lower_case)\n",
        "            model.to(training_args.device)\n",
        "\n",
        "\n",
        "            dataset = eval_dataset.dataset\n",
        "            examples = eval_dataset.examples\n",
        "            features = eval_dataset.features\n",
        "            eval_batch_size = training_args.per_gpu_eval_batch_size * max(1, training_args.n_gpu)\n",
        "\n",
        "            eval_sampler = SequentialSampler(dataset)\n",
        "            eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=eval_batch_size)\n",
        "\n",
        "            logger.info(\"*** Evaluate ***\")\n",
        "            description = \"Evaluation\"\n",
        "            logger.info(\"***** Running %s *****\", description)\n",
        "            logger.info(\"  Num examples = %d\", len(dataset))\n",
        "            logger.info(\"  Batch size = %d\", eval_batch_size)\n",
        "\n",
        "            all_results = []\n",
        "            start_time = timeit.default_timer()\n",
        "\n",
        "            for batch in tqdm(eval_dataloader, desc=description):\n",
        "                model.eval()\n",
        "                batch = tuple(t.to(training_args.device) for t in batch)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    inputs = {\n",
        "                        \"input_ids\": batch[0],\n",
        "                        \"attention_mask\": batch[1],\n",
        "                        \"token_type_ids\": batch[2],\n",
        "                    }\n",
        "                    feature_indices = batch[3]\n",
        "                    outputs = model(**inputs)\n",
        "\n",
        "                for i, feature_index in enumerate(feature_indices):\n",
        "                    eval_feature = features[feature_index.item()]\n",
        "                    unique_id = int(eval_feature.unique_id)\n",
        "                    output = [output[i].detach().cpu().tolist() for output in outputs]\n",
        "                    start_logits, end_logits = output\n",
        "                    result = SquadResult(unique_id, start_logits, end_logits)\n",
        "                    all_results.append(result)\n",
        "\n",
        "            evalTime = timeit.default_timer() - start_time\n",
        "            logger.info(\"  Evaluation done in total %f secs (%f sec per example)\", evalTime, evalTime / len(dataset))\n",
        "\n",
        "            # Compute predictions\n",
        "            output_prediction_file = os.path.join(training_args.output_dir, \"predictions.json\")\n",
        "            output_nbest_file = os.path.join(training_args.output_dir, \"nbest_predictions.json\")\n",
        "\n",
        "            output_null_log_odds_file = os.path.join(training_args.output_dir, \"null_odds.json\") \\\n",
        "                if data_args.version_2_with_negative else None\n",
        "\n",
        "            predictions = compute_predictions_logits(\n",
        "                all_examples=examples,\n",
        "                all_features=features,\n",
        "                all_results=all_results,\n",
        "                n_best_size=data_args.n_best_size,\n",
        "                max_answer_length=data_args.max_answer_length,\n",
        "                do_lower_case=model_args.do_lower_case,\n",
        "                output_prediction_file=output_prediction_file,\n",
        "                output_nbest_file=output_nbest_file,\n",
        "                output_null_log_odds_file=output_null_log_odds_file,\n",
        "                verbose_logging=False,\n",
        "                version_2_with_negative=data_args.version_2_with_negative,\n",
        "                null_score_diff_threshold=data_args.null_score_diff_threshold,\n",
        "                tokenizer=tokenizer,\n",
        "            )\n",
        "\n",
        "            # Compute the F1 and exact scores.\n",
        "            eval_result = squad_evaluate(examples, predictions)\n",
        "\n",
        "            output_eval_file = os.path.join(training_args.output_dir, f\"eval_results.txt\")\n",
        "            with open(output_eval_file, \"w\") as writer:\n",
        "                logger.info(\"***** Eval results *****\")\n",
        "                for key, value in eval_result.items():\n",
        "                    logger.info(\"  %s = %s\", key, value)\n",
        "                    writer.write(\"%s = %s\\n\" % (key, value))\n",
        "\n",
        "            eval_results.update(eval_result)\n",
        "\n",
        "\n",
        "        elif task_type == \"sequence_labeling\":\n",
        "            def align_predictions(predictions: np.ndarray, label_ids: np.ndarray) -> Tuple[List[int], List[int]]:\n",
        "                preds = np.argmax(predictions, axis=2)\n",
        "                batch_size, seq_len = preds.shape\n",
        "                label_list = [[] for _ in range(batch_size)]\n",
        "                pred_list = [[] for _ in range(batch_size)]\n",
        "\n",
        "                for i in range(batch_size):\n",
        "                    for j in range(seq_len):\n",
        "                        if label_ids[i, j] != torch.nn.CrossEntropyLoss().ignore_index:\n",
        "                            label_list[i].append(label_map[label_ids[i][j]])\n",
        "                            pred_list[i].append(label_map[preds[i][j]])\n",
        "                return pred_list, label_list\n",
        "\n",
        "            def compute_metrics_fn(p: EvalPrediction) -> Dict:\n",
        "                pred_list, label_list = align_predictions(p.predictions, p.label_ids)\n",
        "                return {\n",
        "                    \"accuracy_score\": accuracy_score(label_list, pred_list),\n",
        "                    \"precision\": precision_score(label_list, pred_list),\n",
        "                    \"recall\": recall_score(label_list, pred_list),\n",
        "                    \"f1\": f1_score(label_list, pred_list),\n",
        "                }\n",
        "\n",
        "            trainer.compute_metrics = compute_metrics_fn\n",
        "            eval_result = trainer.evaluate(eval_dataset=eval_dataset)\n",
        "\n",
        "            output_eval_file = os.path.join(training_args.output_dir, f\"eval_results.txt\")\n",
        "            with open(output_eval_file, \"w\") as writer:\n",
        "                logger.info(\"***** Eval results *****\")\n",
        "                for key, value in eval_result.items():\n",
        "                    logger.info(\"  %s = %s\", key, value)\n",
        "                    writer.write(\"%s = %s\\n\" % (key, value))\n",
        "\n",
        "            eval_results.update(eval_result)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid task type.\")\n",
        "    return eval_results\n",
        "\n",
        "\n",
        "print('setup complete')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "setup complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfWAtDLLx8SK"
      },
      "source": [
        "## Fine-tuning BERT for text classification\n",
        "Now, let's use `BERT` to solve a sentiment classification task. Specifically, we'll be using the Stanford Sentiment Treebank [(Socher et al., 2013)](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf), which was constructed from movie reviews data. We provide code to fine-tune BERT in a separate [\"useful code\" Colab notebook](https://colab.research.google.com/drive/1nJWA9rPkPrjjjtwN_vKUSQoomdfWLAFV?usp=sharing), so check that out if you're interested. However, since training on the full `SST` dataset (67K examples) takes a while, we provide you with a fine-tuned model to save time. Run the following cell to download the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='RED' size='+3'>NEW</font>"
      ],
      "metadata": {
        "id": "9XzEFcNQ3mB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = drive.CreateFile({'id': '1ZJ1_gWahH_OOBIrRm0aN9i8nvLB2olZC'})\n",
        "data_file.GetContentFile('bert-base-cased-finetuned-sst.zip')\n",
        "\n",
        "# Extract the data from the zipfile and put it into pretrained_models_dir\n",
        "with zipfile.ZipFile('bert-base-cased-finetuned-sst.zip', 'r') as zip_file:\n",
        "    zip_file.extractall(pretrained_models_dir)\n",
        "os.remove('bert-base-cased-finetuned-sst.zip')\n",
        "print(\"bert-base-cased-finetuned-sst downloaded!\")"
      ],
      "metadata": {
        "id": "Fut9TAtM3ah-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b3abbf-522c-4634-ecbf-86cb391575fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert-base-cased-finetuned-sst downloaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMugs2KHRUZN"
      },
      "source": [
        "### Question 2.2 (5 points)\n",
        "Let's use the trained model to predict the sentiment of a given sentence. We will make a few predictions in the code below. Your task is to complete the code to print out the model's predicted probability distribution for each sentence.\n",
        "\n",
        "*Hint:*\n",
        "\n",
        "*   `model(inputs)[0]` gives you the logits of the model for `inputs`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlaiLg-a5f8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f624e57-7dbd-4cc4-d132-c0cbc8c2e5b8"
      },
      "source": [
        "# Load the trained model and make a few predictions\n",
        "model_name_or_path = \"bert-base-cased-finetuned-sst\"\n",
        "pretrained_weights = os.path.join(pretrained_models_dir, model_name_or_path)\n",
        "task_type = \"text_classification\"\n",
        "model = AUTO_MODEL[task_type].from_pretrained(pretrained_weights)\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_weights)\n",
        "\n",
        "classes = [\"negative\", \"positive\"]\n",
        "\n",
        "sentence_1 = \"the movie has something interesting to say\"\n",
        "sentence_2 = \"it was so awful that i walked out after 30 minutes :(\"\n",
        "\n",
        "inputs_1 = tokenizer.encode(sentence_1, add_special_tokens=True, return_tensors=\"pt\")\n",
        "inputs_2 = tokenizer.encode(sentence_2, add_special_tokens=True, return_tensors=\"pt\")\n",
        "\n",
        "# YOUR CODE HERE!\n",
        "probabilities_1 = torch.nn.functional.softmax(model(inputs_1)[0], dim=-1)[0].tolist()\n",
        "probabilities_2 = torch.nn.functional.softmax(model(inputs_2)[0], dim=-1)[0].tolist()\n",
        "\n",
        "print('Sentence: ', sentence_1)\n",
        "print('Prob for negative class: ', probabilities_1[0])\n",
        "print('Prob for positive class: ', probabilities_1[1])\n",
        "\n",
        "print()\n",
        "\n",
        "print('Sentence: ', sentence_2)\n",
        "print('Prob for negative class: ', probabilities_2[0])\n",
        "print('Prob for positive class: ', probabilities_2[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  the movie has something interesting to say\n",
            "Prob for negative class:  0.0011133861262351274\n",
            "Prob for positive class:  0.9988866448402405\n",
            "\n",
            "Sentence:  it was so awful that i walked out after 30 minutes :(\n",
            "Prob for negative class:  0.9978280663490295\n",
            "Prob for positive class:  0.002171869855374098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLdj1V1yZnSO"
      },
      "source": [
        "### Question 2.3 (5 points)\n",
        "Come up with a new sentence that the model gets wrong. The sentence must contain some sentiment (i.e., it cannot be neutral), and the model should place a higher probability on the wrong label than the correct one. Show the model's prediction on this new sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmKYU5zratKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d440e9-f770-4037-a8dd-65d032c6ee9e"
      },
      "source": [
        "your_sentence = \"Sure, if you enjoy watching paint dry for two hours, this masterpiece is for you!\" # change to your sentence\n",
        "your_sentence_sentiment = 'negative' # change to your sentence's ground-truth sentiment\n",
        "your_model_prediction = [] # obviously, change this to the model's prediction on your sentence\n",
        "\n",
        "# YOUR CODE HERE\n",
        "sent = tokenizer.encode(your_sentence, add_special_tokens=True, return_tensors=\"pt\")\n",
        "probabilities = torch.nn.functional.softmax(model(sent)[0], dim=-1)\n",
        "your_model_prediction = probabilities[0].tolist()\n",
        "\n",
        "\n",
        "print('your sentence: \"%s\"\\nground-truth label: %s\\npredicted negative prob: %0.2f\\npredicted positive prob: %0.2f'\\\n",
        "      % (your_sentence, your_sentence_sentiment, your_model_prediction[0], your_model_prediction[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your sentence: \"Sure, if you enjoy watching paint dry for two hours, this masterpiece is for you!\"\n",
            "ground-truth label: negative\n",
            "predicted negative prob: 0.01\n",
            "predicted positive prob: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTdT62X1cSfg"
      },
      "source": [
        "### Question 2.4 (5 points)\n",
        "Provide a reasonable explanation as to why the model got your sentence wrong. Also provide a plausible method to improve the underlying sentiment model so that this kind of error stops happening.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sosXqVsIfAOc"
      },
      "source": [
        "***WRITE YOUR ANSWER HERE IN A FEW SENTENCES***\n",
        "\n",
        "This sentence has some kind of `Sarcasm` in it and that is why the model predicted wrong class for it. In a text with sarcasm, although we say something positive apparently, but we mean something negative actually. LMs usually have this weakness to detect this sentences correctly.\n",
        "\n",
        "To overcome this problem, a solution could be fine-tuning on dataset with sarcastic text. It will help the model to recognize this kind of text and classifiy them correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt4_JfmX7w5d"
      },
      "source": [
        "## Fine-tuning BERT for question answering\n",
        "In this section, we will use `BERT` for a question answering task, i.e., `SQuAD` [(Rajpurkar et al., 2016)](https://nlp.stanford.edu/pubs/rajpurkar2016squad.pdf) whose dataset was built from Wikipedia. Training on the full `SQuAD` dataset (108K examples) would takes a couple of hours, so we will provide you with a trained model to save your time. Run the following cell to download the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMhmA6i61Cqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ca04c7-6353-440b-abc9-dca7264837d5"
      },
      "source": [
        "data_file = drive.CreateFile({'id': '19cnGSN88KlRJRcIqwxw3C4ylJftdkZ2W'})\n",
        "data_file.GetContentFile('bert-base-cased-finetuned-squad.zip')\n",
        "\n",
        "# Extract the data from the zipfile and put it into pretrained_models_dir\n",
        "with zipfile.ZipFile('bert-base-cased-finetuned-squad.zip', 'r') as zip_file:\n",
        "    zip_file.extractall(pretrained_models_dir)\n",
        "os.remove('bert-base-cased-finetuned-squad.zip')\n",
        "print(\"bert-base-cased-finetuned-squad downloaded!\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert-base-cased-finetuned-squad downloaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CkbeUxR5fNw"
      },
      "source": [
        "### Question 2.5 (10 points)\n",
        "\n",
        "Okay, same drill as before! Your task is to complete the code to show the model's predicted answer to each question. If you forgot how `BERT` solves extractive question answering tasks, check out Section 4.2 and Figure 1 / Figure 4c) in the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf). Your output should be three strings, each corresponding to the answer of one of the three given questions.\n",
        "\n",
        "*Hints*\n",
        "\n",
        "*   `model(**inputs)]` gives you the start and end logits of the model for  `inputs`.\n",
        "*   Use `tokenizer.convert_tokens_to_string` to convert a sequence of tokens (string) into a single string.\n",
        "*   Use `tokenizer.convert_ids_to_tokens` to convert a sequence of indices into a sequence of tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5COVCSw6f5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e81e88e-68ee-46db-d499-caf015684e24"
      },
      "source": [
        "task_name = \"SQuAD\"\n",
        "model_name_or_path = \"bert-base-cased-finetuned-squad\"\n",
        "pretrained_weights = os.path.join(pretrained_models_dir, model_name_or_path)\n",
        "task_type = \"question_answering\"\n",
        "model = AUTO_MODEL[task_type].from_pretrained(pretrained_weights)\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_weights)\n",
        "\n",
        "context = \"\"\"This course will broadly focus on deep learning methods for\n",
        "natural language processing. Most of the semester will focus on very recent\n",
        "transfer learning methods that have significantly pushed forward the state of\n",
        "the art. It is intended for graduate students in computer science and\n",
        "linguistics who are (1) interested in learning about cutting-edge research\n",
        "progress in NLP and (2) familiar with machine learning fundamentals. We will\n",
        "cover modeling architectures, training objectives, and downstream tasks (e.g.,\n",
        "text classification, question answering, and text generation). Coursework\n",
        "includes reading recent research papers, programming assignments, and a final\n",
        "project. This class will be asynchronous: lectures will be prerecorded and\n",
        "posted on a weekly basis, along with accompanying readings and assignments.\"\"\"\n",
        "\n",
        "questions = [\n",
        "    \"What is the focus of this course?\",\n",
        "    \"Who is this course intended for?\",\n",
        "    \"What is the coursework?\",\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "\n",
        "\n",
        "    # YOUR CODE HERE!\n",
        "    # Predict start and end logits\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
        "\n",
        "    # Identify the most likely answer span\n",
        "    answer_start = torch.argmax(start_logits).item()\n",
        "    answer_end = torch.argmax(end_logits).item()\n",
        "\n",
        "    # Validate answer span (ensure it's within context bounds)\n",
        "    if answer_end < answer_start or answer_end >= len(input_ids):\n",
        "        print(f\"Question: {question}\")\n",
        "        print(\"Invalid answer span detected. Skipping prediction.\")\n",
        "        continue\n",
        "\n",
        "    # Convert answer tokens back to text\n",
        "    answer_tokens = tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end+1])\n",
        "    answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
        "\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Predicted Answer: {answer}\")\n",
        "    print()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ./pretrained_models_dir/bert-base-cased-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the focus of this course?\n",
            "Predicted Answer: deep learning methods for natural language processing\n",
            "\n",
            "Question: Who is this course intended for?\n",
            "Predicted Answer: graduate students in computer science and linguistics\n",
            "\n",
            "Question: What is the coursework?\n",
            "Predicted Answer: reading recent research papers, programming assignments, and a final project\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjPQa9bGhNKL"
      },
      "source": [
        "### Question 2.6 (5 points)\n",
        "Come up with a new question about this passage that the model gets wrong. The question must be answerable by the passage (i.e., its ground-truth answer should be a span of text within the passage). Show the model's predicted answer on this new sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJJeSHlZhfgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5591a54f-6ce1-42a9-97a5-2575451730c0"
      },
      "source": [
        "your_question = 'What prerequisites are recommended for students interested in enrolling in the course?' # change to your question\n",
        "your_answer = '(1) interested in learning about cutting-edge research progress in NLP and (2) familiar with machine learning fundamentals' # change to your sentence's ground-truth answer\n",
        "your_model_prediction = '' # obviously, change this to the model's predicted answer span\n",
        "\n",
        "\n",
        "# YOUR CODE HERE\n",
        "inputs = tokenizer.encode_plus(your_question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
        "input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "\n",
        "\n",
        "# Predict start and end logits\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
        "\n",
        "# Identify the most likely answer span\n",
        "answer_start = torch.argmax(start_logits).item()\n",
        "answer_end = torch.argmax(end_logits).item()\n",
        "\n",
        "# Validate answer span (ensure it's within context bounds)\n",
        "if answer_end < answer_start or answer_end >= len(input_ids):\n",
        "    print(f\"Question: {question}\")\n",
        "    print(\"Invalid answer span detected. Skipping prediction.\")\n",
        "\n",
        "# Convert answer tokens back to text\n",
        "answer_tokens = tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end+1])\n",
        "answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
        "your_model_prediction = answer.replace(\" ##\", \"\")  # Remove separator token if present\n",
        "\n",
        "\n",
        "print('your question: \"%s\"\\nground-truth answer: %s\\npredicted answer: %s'\\\n",
        "      % (your_question, your_answer, your_model_prediction))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your question: \"What prerequisites are recommended for students interested in enrolling in the course?\"\n",
            "ground-truth answer: prerecorded\n",
            "predicted answer: [CLS]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyS1OJ6sh70y"
      },
      "source": [
        "### Question 2.7 (5 points)\n",
        "Provide a reasonable explanation as to why the model got your question wrong. Also provide a plausible method to improve the underlying QA model so that this kind of error stops happening."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb24NVS_h70z"
      },
      "source": [
        "***WRITE YOUR ANSWER HERE IN A FEW SENTENCES***\n",
        "\n",
        "It is obvious that model failed to answer this question and just returned [CLS] token.\n",
        "\n",
        "It could have several reasons. One reason could be beucase of the fact that model couldn't actually understand that what question wanted. In the context, we do not have a direct reference to `prerequisites` but we had the expression that say that it was intended for which kind of students. On the other side, this question has a longer answer than the previous question. Maybe the model has problen to capture long term denepdencies.\n",
        "\n",
        "One strategy to overcome this problem could be fine-tuning on question-answering dataset that had more diverse set of questions to help the model really capture the context of question. Also we need to have longer answers in this dataset to improve dependency range of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI Disclosure\n",
        "\n",
        "*   Did you use any AI assistance to complete this homework? If so, please also specify what AI you used.\n",
        "    * ChatGPT / Gemini\n",
        "\n",
        "\n",
        "---\n",
        "*(only complete the below questions if you answered yes above)*\n",
        "\n",
        "*   If you used a large language model to assist you, please paste *all* of the prompts that you used below. Add a separate bullet for each prompt, and specify which problem is associated with which prompt.\n",
        "    * Link to chatgpt responses: https://chat.openai.com/share/f05c63dc-0c21-448d-9864-b073db60a731\n",
        "    * Link to Gemini responses: https://g.co/gemini/share/5ea5443ed6ed\n",
        "*   **Free response**: For each problem for which you used assistance, describe your overall experience with the AI. How helpful was it? Did it just directly give you a good answer, or did you have to edit it? Was its output ever obviously wrong or irrelevant? Did you use it to get the answer or check your own answer?\n",
        "    * It depends on the the type of question. For some of the question, it gave me completely correct answers. For example for most of coding and explanation question, Responses had good quality but for questions that need to generate a question or text based on the conditions or interpreting results, there were some mistakes.\n",
        "    * I used in both cases, getting the answer and checking the answer. I also used them to improve the quality of my reports for questions by asking them to rewrite them.\n",
        "    * I utilized both Gemini and ChatGPT and each of them was better in some usecases but in overall Gemini had better results.\n"
      ],
      "metadata": {
        "id": "HL8W-Ku8tVLT"
      }
    }
  ]
}