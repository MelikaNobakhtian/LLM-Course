{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALnEUrLq1-kp"
      },
      "source": [
        "## CA 2, LLMs Spring 2024\n",
        "\n",
        "- **Name:** Melika Noubakhtian\n",
        "- **Student ID:** 4021305965008\n",
        "\n",
        "---\n",
        "#### Your submission should be named using the following format: `CA2_LASTNAME_STUDENTID_soft_prompt.ipynb`.\n",
        "\n",
        "- There is no penalty for using AI assistance on this homework as long as you fully disclose it in the final cell of this notebook (this includes storing any prompts that you feed to large language models). That said, anyone caught using AI assistance without proper disclosure will receive a zero on the assignment (we have several automatic tools to detect such cases). We're literally allowing you to use it with no limitations, so there is no reason to lie!\n",
        "\n",
        "---\n",
        "\n",
        "##### *Academic honesty*\n",
        "\n",
        "- We will audit the Colab notebooks from a set number of students, chosen at random. The audits will check that the code you wrote actually generates the answers in your notebook. If you turn in correct answers on your notebook without code that actually generates those answers, we will consider this a serious case of cheating.\n",
        "\n",
        "- We will also run automatic checks of Colab notebooks for plagiarism. Copying code from others is also considered a serious case of cheating.\n",
        "\n",
        "---\n",
        "\n",
        "If you have any further questions or concerns, contact the TA via email:\n",
        "mohammad136631@gmail.com\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfrgatGB3Aac"
      },
      "source": [
        "# What are Soft prompts?\n",
        "Soft prompts are learnable tensors concatenated with the input embeddings that can be optimized to a dataset; the downside is that they aren’t human readable because you aren’t matching these “virtual tokens” to the embeddings of a real word.\n",
        "<br>\n",
        "<div>\n",
        "<img src=\"https://www.researchgate.net/publication/366062946/figure/fig1/AS:11431281105340756@1670383256990/The-comparison-between-the-previous-T5-prompt-tuning-method-part-a-and-the-introduced.jpg\"/>\n",
        "</div>\n",
        "\n",
        "Read More:\n",
        "<br>[Youtube : PEFT and Soft Prompt](https://www.youtube.com/watch?v=8uy_WII76L0)\n",
        "<br>[Paper: The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/pdf/2104.08691.pdf)\n",
        "https://arxiv.org/pdf/2101.00190.pdf\n",
        "<br>[Paper: Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/pdf/2101.00190.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLaYIRN4X7cC"
      },
      "source": [
        "# Part 1 (20 Points)\n",
        "Before diving into the practical applications, let's first ensure your foundational knowledge is solid. Please answer the following questions.\n",
        "\n",
        "\n",
        "**A) Compare and contrast model tuning and prompt tuning in terms of their effectiveness for specific downstream tasks. (5 Points)**\n",
        "\n",
        "**B) Explore the challenges associated with interpreting soft prompts in the continuous embedding space and propose potential solutions. (5 Points)**\n",
        "\n",
        "**C) What is the effect of initializing prompts randomly versus initializing them from the vocabulary, and how does this impact the performance of prompt tuning? (5 Points)**\n",
        "\n",
        "**D) How is the optimization process in the prefix tuning(<br>[Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/pdf/2101.00190.pdf)) and Why did they use this technique? (5 Points)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9CqqGdLMpvO"
      },
      "source": [
        "# Answer:\n",
        "\n",
        "**Part (a):**\n",
        "\n",
        "- **Prompt Tuning:**\n",
        "  - Involves updating only the prompt weights while keeping the model weights fixed.\n",
        "  - Eliminates the need for separate base models for each task by introducing specific virtual tokens for individual tasks.\n",
        "  - Recognized for its efficiency, particularly with larger models.\n",
        "  - May not yield optimal results with smaller models due to their limited capacity.\n",
        "\n",
        "- **Model Tuning:**\n",
        "  - Entails modifying the model weights directly.\n",
        "  - Requires maintaining distinct model versions for each task, resulting in greater storage and memory demands.\n",
        "  - Offers flexibility in adapting the underlying architecture of the model, potentially leading to improved performance across a broader range of tasks.\n",
        "  - Particularly effective for tasks where significant adjustments to the model architecture are necessary to capture task-specific nuances.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEpnC3m1ZNet"
      },
      "source": [
        "**Part (b):**\n",
        "\n",
        "**Challenges:**\n",
        "\n",
        "1. **Curse of Dimensionality:** Continuous embedding spaces can have hundreds or even thousands of dimensions. Visualizing or reasoning about such high-dimensional spaces is incredibly difficult.\n",
        "\n",
        "2. **Context Dependence:** Embeddings can shift their meaning depending on the surrounding context.  So we can not just interpret the word embeddings by themselves and the words around them are important.\n",
        "\n",
        "4. **ُSpecific Words:** A prompt is interpretable for human if it contains meaningful words but continous embedding in many cases do not show certain words and it will be hard for us to understand the reason for choosing them.\n",
        "\n",
        "\n",
        "## Potential Solutions\n",
        "\n",
        "\n",
        "1. **Dimensionality Reduction Techniques:** Techniques like Principal Component Analysis (PCA) can project the high-dimensional embedding space into a lower-dimensional one, allowing for better visualization and analysis of the prompt's influence.\n",
        "\n",
        "2. **Attention Mechanisms:** Examining the attention weights assigned by the LLM during generation can provide insights into which parts of the soft prompt embeddings were most influential in generating specific parts of the output.\n",
        "\n",
        "3. **Mapping to nearest words**: Trying to map a continous embedding to a word that is near to it will help us to have meaningful words instead of just some numbers and we can explain them in a better way.\n",
        "\n",
        "4. **Explainable AI (XAI) Techniques:** Integrating XAI methods into LLMs can help explain the internal decision-making processes during generation. This could shed light on how the model interprets and utilizes the soft prompt information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l-HOEtia80r"
      },
      "source": [
        "**Part (c):**\n",
        "\n",
        "**Random Initialization:**\n",
        "\n",
        "* **Effect:**\n",
        "    * Introduces a high degree of variability in the initial prompt. This can be beneficial for exploration, potentially leading to discovering unexpected directions for the model.\n",
        "    * However, random initialization often leads to prompts with little semantic meaning, requiring the model to work harder to learn a meaningful representation.\n",
        "* **Impact on Performance:**\n",
        "    * Can be slow and inefficient, requiring many iterations of prompt tuning to find effective configurations.\n",
        "    * May lead to prompts that are nonsensical or nonsyntactic.\n",
        "\n",
        "**Vocabulary-based Initialization:**\n",
        "\n",
        "* **Effect:**\n",
        "    * Starts with prompts that at least have meaningful tokens and potentially hold some semantic meaning based on the chosen words.\n",
        "    * This provides a better foundation for the model to build upon during prompt tuning.\n",
        "* **Impact on Performance:**\n",
        "    * Generally leads to faster convergence during prompt tuning as the starting point is closer to a potentially useful prompt.\n",
        "    * Offers more control over the initial direction of the prompt, allowing for targeted tuning towards specific functionalities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-EG6W6feCYm"
      },
      "source": [
        "**Part(d):**\n",
        "\n",
        " How it works and why we should use it:\n",
        "\n",
        "1. **Fine-tuning vs. Prefix-Tuning**:\n",
        "   - Fine-tuning modifies all the language model parameters, which necessitates storing a full copy for each task.\n",
        "   - In contrast, prefix-tuning keeps the language model parameters frozen and optimizes a small continuous task-specific vector (referred to as the \"prefix\"). This approach allows for more efficient parameter updates.\n",
        "\n",
        "2. **Optimization Process**:\n",
        "   - During prefix-tuning, the language model parameters remain fixed, and only the prefix vector is updated.\n",
        "   - The prefix serves as a context for subsequent tokens, allowing them to attend to it as if it were \"virtual tokens.\"\n",
        "   - By learning only 0.1% of the parameters, prefix-tuning achieves comparable performance to fine-tuning in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics unseen during training.\n",
        "\n",
        "3. **Applications**:\n",
        "   - The authors apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization.\n",
        "   - Notably, prefix-tuning demonstrates promising results with significantly fewer parameters, making it an attractive alternative for certain natural language generation tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQMgi75DV-bo"
      },
      "source": [
        "# Part 2 (35 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3gjmZROpLP5"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG_yY6ep9C7S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import transformers\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_UcfBmLpRiJ"
      },
      "source": [
        "## Model Selection & Constants\n",
        "We will use `bert-fa-base-uncased` as our base model from Hugging Face ([HF_Link](https://huggingface.co/HooshvareLab/bert-fa-base-uncased)). For our tuning, we intend to utilize 20 soft prompt tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV2aP8bwV-z5"
      },
      "outputs": [],
      "source": [
        "class CONFIG:\n",
        "    seed = 42\n",
        "    max_len = 128\n",
        "    train_batch = 16\n",
        "    valid_batch = 32\n",
        "    epochs = 10\n",
        "    n_tokens=20\n",
        "    learning_rate = 0.01\n",
        "    model_name = 'HooshvareLab/bert-fa-base-uncased'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T0asPslpkSh"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset contains around 7000 Persian sentences and their corresponding polarity, and have been manually classified into 5 categories (i.e. Angry)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xpsgvYumvNa"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2JmHJ2wpoaX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "file_path = \"/content/softprompt_dataset.csv\"\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmviyjCrz6mi"
      },
      "source": [
        "### Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PITqCGDx0McE"
      },
      "outputs": [],
      "source": [
        "%pip install -U clean-text[gpl]\n",
        "%pip install hazm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0Nlfm0qE_1P"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from cleantext import clean\n",
        "from hazm import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4CFqPaV0Pqp"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def cleanhtml(raw_html):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', raw_html)\n",
        "    return cleantext\n",
        "\n",
        "def cleaning(text):\n",
        "    text = text.strip()\n",
        "\n",
        "    # regular cleaning\n",
        "    text = clean(text,\n",
        "        fix_unicode=True,\n",
        "        to_ascii=False,\n",
        "        lower=True,\n",
        "        no_line_breaks=True,\n",
        "        no_urls=True,\n",
        "        no_emails=True,\n",
        "        no_phone_numbers=True,\n",
        "        no_numbers=False,\n",
        "        no_digits=False,\n",
        "        no_currency_symbols=True,\n",
        "        no_punct=False,\n",
        "        replace_with_url=\"\",\n",
        "        replace_with_email=\"\",\n",
        "        replace_with_phone_number=\"\",\n",
        "        replace_with_number=\"\",\n",
        "        replace_with_digit=\"0\",\n",
        "        replace_with_currency_symbol=\"\",\n",
        "    )\n",
        "\n",
        "    text = cleanhtml(text)\n",
        "\n",
        "    # normalizing\n",
        "    #normalizer = hazm.Normalizer()\n",
        "    #text = normalizer.normalize(text)\n",
        "\n",
        "    wierd_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u'\\U00010000-\\U0010ffff'\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\u3030\"\n",
        "        u\"\\ufe0f\"\n",
        "        u\"\\u2069\"\n",
        "        u\"\\u2066\"\n",
        "        u\"\\u2068\"\n",
        "        u\"\\u2067\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    text = wierd_pattern.sub(r'', text)\n",
        "\n",
        "    # removing extra spaces, hashtags\n",
        "    text = re.sub(\"#\", \"\", text)\n",
        "    text = re.sub(\"\\s+\", \" \", text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_5ZyotA0cxw"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "def parallel_apply_with_progress(df, func, n_workers=4):\n",
        "    with ThreadPoolExecutor(max_workers=n_workers) as executor, tqdm(total=len(df)) as pbar:\n",
        "        def update(*args):\n",
        "            pbar.update()\n",
        "\n",
        "        results = []\n",
        "        for result in executor.map(func, df['text']):\n",
        "            results.append(result)\n",
        "            update()\n",
        "\n",
        "        df['text'] = pd.Series(results)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APUjLG3E0qxK",
        "outputId": "129cf232-8d71-4ba9-b96f-876e3b9fb5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7023/7023 [00:02<00:00, 3278.45it/s]\n"
          ]
        }
      ],
      "source": [
        "df = parallel_apply_with_progress(df, cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2tZk2fBSwJL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values,\n",
        "                                                  df.label.values,\n",
        "                                                  test_size=0.15,\n",
        "                                                  random_state=42,\n",
        "                                                  stratify=df.label.values)\n",
        "\n",
        "train_df = df.loc[X_train]\n",
        "validation_df = df.loc[X_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GTgl8-RV926",
        "outputId": "3b8df12c-0f62-4423-9fc2-5f7b6089d4ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0, 1: 1, 2: 2, -1: 3, -2: 4}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "possible_labels = df.label.unique()\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgTnO4ctWKqo"
      },
      "outputs": [],
      "source": [
        "train_df['label'] = train_df.label.replace(label_dict)\n",
        "validation_df['label'] = validation_df.label.replace(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqIWHJ9XMiOr"
      },
      "source": [
        "### Create Dataset Class (5 Points)\n",
        "In this step we will getting our dataset ready for training.\n",
        "\n",
        "In this part we will define BERT-based dataset class for text classification, with configuration parameters. It preprocesses text data and tokenizes it using the BERT tokenizer.\n",
        "\n",
        "\n",
        "Complete the preprocessing step in the __getitem__ method by adding padding tokens to 'input_ids' and 'attention_mask',\n",
        "The count of this pad tokens is the same as `n_tokens`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyS6DyeZ75bZ"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self,df):\n",
        "        self.text = df['text'].values\n",
        "        self.labels = df['label'].values\n",
        "        self.all_labels = [0, 1, 2, 3, 4]\n",
        "        self.max_len = CONFIG.max_len\n",
        "        self.tokenizer = CONFIG.tokenizer\n",
        "        self.n_tokens=CONFIG.n_tokens\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.text[index]\n",
        "        text = ' '.join(text.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        ######### Your code begins #########\n",
        "        inputs['input_ids'] = torch.tensor([self.tokenizer.pad_token_id] * self.n_tokens + inputs['input_ids'])\n",
        "        inputs['attention_mask'] = torch.tensor([1] * (self.n_tokens) + inputs['attention_mask'])\n",
        "        ######### Your code ends ###########\n",
        "\n",
        "        labels = self.labels[index]\n",
        "        label_dict = {label: (label == labels) for label in self.all_labels}\n",
        "        labels_tensor = torch.tensor([float(label_dict[label]) for label in self.all_labels])\n",
        "        return {\n",
        "            'ids': inputs['input_ids'],\n",
        "            'mask': inputs['attention_mask'],\n",
        "            'label': labels_tensor\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf8AYo8cFiud"
      },
      "outputs": [],
      "source": [
        "train_dataset = BERTDataset(train_df)\n",
        "validation_dataset = BERTDataset(validation_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSWkTORNcxvx"
      },
      "source": [
        "## Define Prompt Embedding Layer (15 Points)\n",
        "In this part we will define our prompt layer in `PROMPTEmbedding` module.\n",
        "\n",
        "\n",
        "<font color='#73FF73'><b>You have to complete</b></font> `initialize_embedding` and  `forward` <font color='#73FF73'><b>functions.</b></font>\n",
        "\n",
        "In `initialize_embedding` function initialize the learned embeddings based on whether they should be initialized from the vocabulary or randomly within the specified range.\n",
        "\n",
        "In `forward` function, modify the input_embedding to extract the relevant part based on n_tokens.\n",
        "\n",
        "Repeat the learned_embedding to match the size of input_embedding.\n",
        "\n",
        "Concatenate the learned_embedding and input_embedding properly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tqAU4Ubj2t8"
      },
      "outputs": [],
      "source": [
        "class PROMPTEmbedding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_layer: nn.Embedding,\n",
        "                 n_tokens: int = 20,\n",
        "                 random_range: float = 0.5,\n",
        "                 initialize_from_vocab: bool = True):\n",
        "\n",
        "        super(PROMPTEmbedding, self).__init__()\n",
        "        self.emb_layer = emb_layer\n",
        "        self.n_tokens = n_tokens\n",
        "        self.learned_embedding = nn.parameter.Parameter(self.initialize_embedding(emb_layer,\n",
        "                                                                                   n_tokens,\n",
        "                                                                                   random_range,\n",
        "                                                                                   initialize_from_vocab))\n",
        "\n",
        "    def initialize_embedding(self,\n",
        "                             emb_layer: nn.Embedding,\n",
        "                             n_tokens: int = 20,\n",
        "                             random_range: float = 0.5,\n",
        "                             initialize_from_vocab: bool = True):\n",
        "\n",
        "        if initialize_from_vocab:\n",
        "            # Initialize embeddings from the vocabulary\n",
        "            vocab_emb = emb_layer.weight[:n_tokens]\n",
        "            return vocab_emb\n",
        "        else:\n",
        "            # Initialize embeddings randomly within the specified range\n",
        "            random_emb = torch.rand(n_tokens, emb_layer.embedding_dim).uniform_(-random_range, random_range)\n",
        "            return random_emb\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        ######### Your code begins #########\n",
        "        ext_input_embedding = self.emb_layer(tokens[:, self.n_tokens:])\n",
        "        learned_embedding = self.learned_embedding.unsqueeze(0).repeat(ext_input_embedding.size(0), 1, 1)\n",
        "        concat_embedding = torch.cat([learned_embedding, ext_input_embedding], dim=1)\n",
        "        ######### Your code ends ###########\n",
        "        return concat_embedding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhES_23bDfXZ"
      },
      "source": [
        "## Replace model's embedding layer with our layer (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "d458b45a8e49418193aaafa372701cba"
          ]
        },
        "id": "-AMhjuooOQKA",
        "outputId": "c8280c45-5467-4e20-b316-663b229429a5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d458b45a8e49418193aaafa372701cba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Define your BERT model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(CONFIG.model_name, num_labels=5, output_attentions = False,\n",
        "                                                           output_hidden_states = False).to(CONFIG.device)\n",
        "######### Your code begins #########\n",
        "# Get the word embedding from the BERT model\n",
        "bert_embedding_layer = model.bert.embeddings.word_embeddings\n",
        "\n",
        "# Create an instance of PROMPTEmbedding to replace it\n",
        "prompt_embedding_layer = PROMPTEmbedding(bert_embedding_layer)\n",
        "\n",
        "# Set the embedding of the BERT model to the new PROMPTEmbedding instance\n",
        "model.bert.embeddings.word_embeddings = prompt_embedding_layer\n",
        "\n",
        "######### Your code ends ###########\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wlsc2meajrn"
      },
      "source": [
        "## Freezing Model Parameters (5 points)\n",
        "In this part we will freeze entire model except `learned_embedding`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CCq8Z1lajGC"
      },
      "outputs": [],
      "source": [
        "######### Your code begins #########\n",
        "for name, param in model.named_parameters():\n",
        "    if 'learned_embedding' not in name:  # Exclude the learned_embedding layer\n",
        "        param.requires_grad = False\n",
        "\n",
        "######### Your code ends ###########"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8ud-O_Rrptq"
      },
      "source": [
        "## Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IckuDmDWRye"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=CONFIG.learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17S9KFKM1jgP"
      },
      "source": [
        "## Training & Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZsfsyKAY2yu"
      },
      "source": [
        "### Define dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVRa2SLDWUM9"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch,\n",
        "                              num_workers=2, shuffle=True, pin_memory=True)\n",
        "\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=CONFIG.valid_batch,\n",
        "                              num_workers=2, shuffle=True, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0Sj5pT6ZDbz"
      },
      "source": [
        "### Define evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f-OVsQ5_War"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = np.argmax(labels, axis=1).flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bqs9Hxi9yjz"
      },
      "outputs": [],
      "source": [
        "def evaluate(val_dataloader):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "\n",
        "\n",
        "        inputs = {'input_ids':      batch['ids'].to(CONFIG.device),\n",
        "                  'attention_mask': batch['mask'].to(CONFIG.device),\n",
        "                  'labels':         batch['label'].to(CONFIG.device),\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[\"loss\"]\n",
        "        logits = outputs[\"logits\"]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "\n",
        "    loss_val_avg = loss_val_total/len(val_dataloader)\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "    return loss_val_avg, predictions, true_vals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjO1TwDSZMWH"
      },
      "source": [
        "### Define trainng loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjXZ7oB_1jGv"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_dataloader, val_dataloader):\n",
        "\n",
        "    epochs = CONFIG.epochs\n",
        "\n",
        "    for epoch in tqdm(range(1, epochs+1)):\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      loss_train_total = 0\n",
        "\n",
        "      progress_bar = tqdm(train_loader, desc='Epoch {:1d}'.format(epoch), leave=False, disable=True)\n",
        "\n",
        "      for batch in progress_bar:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs = {'input_ids':      batch['ids'].to(CONFIG.device),\n",
        "                  'attention_mask': batch['mask'].to(CONFIG.device),\n",
        "                  'labels':         batch['label'].to(CONFIG.device),\n",
        "                }\n",
        "        output = model(**inputs)\n",
        "\n",
        "        loss = output[\"loss\"]\n",
        "        loss_train_total += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "\n",
        "\n",
        "      tqdm.write(f'\\nEpoch {epoch}')\n",
        "      loss_train_avg = loss_train_total/len(train_loader)\n",
        "      tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "\n",
        "\n",
        "      val_loss, predictions, true_vals = evaluate(val_dataloader)\n",
        "      val_f1 = f1_score_func(predictions, true_vals)\n",
        "      tqdm.write(f'Validation loss: {val_loss}')\n",
        "      tqdm.write(f'F1 Score (Weighted): {val_f1}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaTI1yeyZW1i"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--yqi1tp1jCv",
        "outputId": "7fa8790b-11bc-4389-e824-3bc20751f6d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [01:42<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.4698566302736813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [01:53<17:03, 113.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4465766151746114\n",
            "F1 Score (Weighted): 0.3042141094704492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [03:44<17:03, 113.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.4407631951698007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [03:54<15:43, 117.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.41510971116297174\n",
            "F1 Score (Weighted): 0.41760541996352235\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [05:44<15:43, 117.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3\n",
            "Training loss: 0.4245450972395147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [05:55<13:54, 119.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4040612822229212\n",
            "F1 Score (Weighted): 0.44267267985414166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [07:46<13:54, 119.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4\n",
            "Training loss: 0.4158958150422509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [07:56<12:00, 120.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3942379454771678\n",
            "F1 Score (Weighted): 0.46508969735608335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [09:47<12:00, 120.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5\n",
            "Training loss: 0.40972501294498137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [09:58<10:02, 120.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39107980692025385\n",
            "F1 Score (Weighted): 0.4497250070674416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [11:48<10:02, 120.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6\n",
            "Training loss: 0.4052949426645901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6/10 [11:59<08:02, 120.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39074160023169086\n",
            "F1 Score (Weighted): 0.49867124138254026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6/10 [13:49<08:02, 120.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7\n",
            "Training loss: 0.4046495989522832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [13:59<06:02, 120.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3831418517864112\n",
            "F1 Score (Weighted): 0.478198945184259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [15:50<06:02, 120.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8\n",
            "Training loss: 0.4013456246033709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8/10 [16:00<04:01, 120.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.38097597884409357\n",
            "F1 Score (Weighted): 0.49900824971274427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8/10 [17:51<04:01, 120.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9\n",
            "Training loss: 0.39893683838971794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9/10 [18:02<02:00, 120.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.37837752428921784\n",
            "F1 Score (Weighted): 0.5046570187767595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9/10 [19:53<02:00, 120.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10\n",
            "Training loss: 0.3984285789058808\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [20:03<00:00, 120.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3806744118531545\n",
            "F1 Score (Weighted): 0.49334732040674817\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train(model=model, optimizer=optimizer, train_dataloader=train_loader, val_dataloader=validation_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_3FYFfIUKeE"
      },
      "source": [
        "## Using OpenDelta library (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yp3_9J0wUBxb"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/thunlp/OpenDelta.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pOwAdIRUIKh"
      },
      "source": [
        "Use `OpenDelta` library to do the same thing. [link](https://opendelta.readthedocs.io/en/latest/modules/deltas.html)\n",
        "\n",
        "For hyperparameters, test with `N_SOFT_PROMPT_TOKENS=10` and `N_SOFT_PROMPT_TOKENS=20` and report them."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenDelta library append soft tokens directly to the prompts so we do not need to add them by ourselves, so we need to initialize our dataset another time them without them."
      ],
      "metadata": {
        "id": "-cXQg2xfs_8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NewBERTDataset(Dataset):\n",
        "    def __init__(self,df):\n",
        "        self.text = df['text'].values\n",
        "        self.labels = df['label'].values\n",
        "        self.all_labels = [0, 1, 2, 3, 4]\n",
        "        self.max_len = CONFIG.max_len\n",
        "        self.tokenizer = CONFIG.tokenizer\n",
        "        self.n_tokens=CONFIG.n_tokens\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.text[index]\n",
        "        text = ' '.join(text.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        labels = self.labels[index]\n",
        "        label_dict = {label: (label == labels) for label in self.all_labels}\n",
        "        labels_tensor = torch.tensor([float(label_dict[label]) for label in self.all_labels])\n",
        "        return {\n",
        "            'ids': torch.tensor(inputs['input_ids']),\n",
        "            'mask': torch.tensor(inputs['attention_mask']),\n",
        "            'label': labels_tensor\n",
        "        }\n"
      ],
      "metadata": {
        "id": "w8kf0Pa-tgY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NewBERTDataset(train_df)\n",
        "validation_dataset = NewBERTDataset(validation_df)"
      ],
      "metadata": {
        "id": "ra7R8tERt6wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch,\n",
        "                              num_workers=2, shuffle=True, pin_memory=True)\n",
        "\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=CONFIG.valid_batch,\n",
        "                              num_workers=2, shuffle=True, pin_memory=True)"
      ],
      "metadata": {
        "id": "_KOhhvpVuEde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results in both cases show competitive performance but when `N_SOFT_PROMPT_TOKENS=10`, we have slightly better performance in terms of F1-score. We can continue this experiment with larger values for `soft_token_num` to see if performance improves or not:"
      ],
      "metadata": {
        "id": "y88vyIYZOWj_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989,
          "referenced_widgets": [
            "29190f91b22f4a04bc5a40b58d2c721b",
            "f49dd890b17a4c74bbaae3506558f644",
            "65a3d14dd163477e979bcde3b6b8ccd8",
            "c772950a29a448cd91e3c3e539d372a8",
            "b7896104a68e4c8cb99c51186a2990dd",
            "a7e00e0d3c5d45feb8720b5ee891eed0",
            "8b3a048ca3364fd1beea1c882617b61e",
            "d43954e2b5824038a2018ed82f9b2f08",
            "54803e8d678649ab8c16f01bea6fe391",
            "36d37c7e88c24284a810e0866b80da3a",
            "17d11336f31b412a8860a6d18cd300c9"
          ]
        },
        "id": "LiNnIlRlUFyS",
        "outputId": "6d311018-55fc-4954-9da5-6e83411a0e63"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29190f91b22f4a04bc5a40b58d2c721b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/10 [01:28<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.4688398495396191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [01:36<14:32, 96.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4527739467042865\n",
            "F1 Score (Weighted): 0.22693251170851797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [03:09<14:32, 96.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.45014101386388994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [03:17<13:14, 99.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.42514780163764954\n",
            "F1 Score (Weighted): 0.4226839638728487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [04:51<13:14, 99.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3\n",
            "Training loss: 0.4381828267465938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3/10 [04:59<11:41, 100.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4208501089702953\n",
            "F1 Score (Weighted): 0.39901451867361704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3/10 [06:32<11:41, 100.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4\n",
            "Training loss: 0.4320531115334302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [06:40<10:03, 100.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.40971773953148816\n",
            "F1 Score (Weighted): 0.3652065080963162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [08:13<10:03, 100.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5\n",
            "Training loss: 0.42674727180106115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [08:21<08:24, 100.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4125773346785343\n",
            "F1 Score (Weighted): 0.42480877483042057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [09:54<08:24, 100.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6\n",
            "Training loss: 0.42502613142531187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [10:02<06:43, 100.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4254924086007205\n",
            "F1 Score (Weighted): 0.3792286737530338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [11:36<06:43, 100.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7\n",
            "Training loss: 0.42459849296087887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [11:44<05:03, 101.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.41107688799048914\n",
            "F1 Score (Weighted): 0.38029761599780254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [13:17<05:03, 101.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8\n",
            "Training loss: 0.4221869628219044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [13:25<03:22, 101.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4014404930851676\n",
            "F1 Score (Weighted): 0.4387404508453415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [14:58<03:22, 101.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9\n",
            "Training loss: 0.4194143962732611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [15:07<01:41, 101.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.40442008141315344\n",
            "F1 Score (Weighted): 0.3887846476841646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [16:40<01:41, 101.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10\n",
            "Training loss: 0.42011230801516036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [16:48<00:00, 100.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4060551804123503\n",
            "F1 Score (Weighted): 0.4215387693294917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "######### Your code begins #########\n",
        "from opendelta import SoftPromptModel\n",
        "model = AutoModelForSequenceClassification.from_pretrained(CONFIG.model_name, num_labels=5, output_attentions = False,\n",
        "                                                           output_hidden_states = False)\n",
        "\n",
        "# CASE 1: N_SOFT_PROMPT_TOKENS=10\n",
        "prompt_model = SoftPromptModel(backbone_model=model, soft_token_num=10, init_range=0.5)\n",
        "\n",
        "prompt_model.freeze_module()\n",
        "\n",
        "model.to(CONFIG.device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=CONFIG.learning_rate)\n",
        "\n",
        "train(model=model, optimizer=optimizer, train_dataloader=train_loader, val_dataloader=validation_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whrxYBhiIeYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805ad714-3ee3-4851-bb0a-0c1255c8868f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/10 [01:39<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.4656994526080269\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [01:48<16:15, 108.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4511566405946558\n",
            "F1 Score (Weighted): 0.25425743122970584\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [03:27<16:15, 108.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.45472557715234907\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [03:36<14:27, 108.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4341157349673184\n",
            "F1 Score (Weighted): 0.3233461068947574\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [05:16<14:27, 108.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3\n",
            "Training loss: 0.4403417745535386\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [05:25<12:38, 108.39s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.41616956663854193\n",
            "F1 Score (Weighted): 0.35909447803248495\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [07:04<12:38, 108.39s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4\n",
            "Training loss: 0.42633764055323475\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [07:13<10:49, 108.22s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.40275415687850025\n",
            "F1 Score (Weighted): 0.4177976331742116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [08:52<10:49, 108.22s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5\n",
            "Training loss: 0.42031978014956184\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [09:01<09:00, 108.17s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4041371995752508\n",
            "F1 Score (Weighted): 0.36334689423794364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [10:40<09:00, 108.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6\n",
            "Training loss: 0.4141849941588978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [10:49<07:12, 108.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.39452579256260034\n",
            "F1 Score (Weighted): 0.45942909108806174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [12:28<07:12, 108.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7\n",
            "Training loss: 0.4091011870273932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [12:37<05:24, 108.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.39395132751175854\n",
            "F1 Score (Weighted): 0.4076876714215705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [14:16<05:24, 108.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8\n",
            "Training loss: 0.4067523095378264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [14:25<03:36, 108.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.40398977380810364\n",
            "F1 Score (Weighted): 0.42743823216317983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [16:05<03:36, 108.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9\n",
            "Training loss: 0.40519137752247364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [16:14<01:48, 108.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.38387309963052924\n",
            "F1 Score (Weighted): 0.5261349742358886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [17:53<01:48, 108.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10\n",
            "Training loss: 0.40254843306732685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [18:02<00:00, 108.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.3869407393715598\n",
            "F1 Score (Weighted): 0.46437329948726763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(CONFIG.model_name, num_labels=5, output_attentions = False,\n",
        "                                                           output_hidden_states = False)\n",
        "\n",
        "# CASE 2: N_SOFT_PROMPT_TOKENS=20\n",
        "prompt_model = SoftPromptModel(backbone_model=model, soft_token_num=20, init_range=0.5)\n",
        "\n",
        "prompt_model.freeze_module()\n",
        "\n",
        "model.to(CONFIG.device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=CONFIG.learning_rate)\n",
        "\n",
        "train(model=model, optimizer=optimizer, train_dataloader=train_loader, val_dataloader=validation_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChJFhF-KRwHv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lhES_23bDfXZ",
        "7Wlsc2meajrn",
        "T8ud-O_Rrptq"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "29190f91b22f4a04bc5a40b58d2c721b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f49dd890b17a4c74bbaae3506558f644",
              "IPY_MODEL_65a3d14dd163477e979bcde3b6b8ccd8",
              "IPY_MODEL_c772950a29a448cd91e3c3e539d372a8"
            ],
            "layout": "IPY_MODEL_b7896104a68e4c8cb99c51186a2990dd"
          }
        },
        "f49dd890b17a4c74bbaae3506558f644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e00e0d3c5d45feb8720b5ee891eed0",
            "placeholder": "​",
            "style": "IPY_MODEL_8b3a048ca3364fd1beea1c882617b61e",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "65a3d14dd163477e979bcde3b6b8ccd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d43954e2b5824038a2018ed82f9b2f08",
            "max": 654226731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54803e8d678649ab8c16f01bea6fe391",
            "value": 654226731
          }
        },
        "c772950a29a448cd91e3c3e539d372a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36d37c7e88c24284a810e0866b80da3a",
            "placeholder": "​",
            "style": "IPY_MODEL_17d11336f31b412a8860a6d18cd300c9",
            "value": " 654M/654M [00:14&lt;00:00, 41.0MB/s]"
          }
        },
        "b7896104a68e4c8cb99c51186a2990dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e00e0d3c5d45feb8720b5ee891eed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3a048ca3364fd1beea1c882617b61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d43954e2b5824038a2018ed82f9b2f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54803e8d678649ab8c16f01bea6fe391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36d37c7e88c24284a810e0866b80da3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17d11336f31b412a8860a6d18cd300c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}